[
  {
    "objectID": "migrating.html",
    "href": "migrating.html",
    "title": "nbdev1 migration",
    "section": "",
    "text": "nbdev v2 is a new from-scratch rewrite of nbdev that’s not backwards compatible. This page describes the changes you need to make to upgrade your nbdev v1 repo to work with the new version. The steps shown here should work on macOS or Linux (including Windows WSL)\nThe biggest change is that nbdev2 uses Quarto to generate your website, whereas nbdev1 used nbconvert and jekyll. You can use all of Quarto’s features directly in nbdev, so checkout the Quarto website to see all the amazing functionality it supports."
  },
  {
    "objectID": "migrating.html#initial-setup",
    "href": "migrating.html#initial-setup",
    "title": "nbdev1 migration",
    "section": "Initial setup",
    "text": "Initial setup\nIf you’ve pinned nbdev in requirements.txt or settings.ini (e.g nbdev<2) remove the version pin. (If you don’t know what this means, then you don’t have it, so you can ignore this step).\nInstall the latest version of nbdev by typing:\npip install -U nbdev\nor:\nconda install -c fastai nbdev\nYou may need to restart your terminal for the new commands to be visible to your shell."
  },
  {
    "objectID": "migrating.html#upgrade-directives",
    "href": "migrating.html#upgrade-directives",
    "title": "nbdev1 migration",
    "section": "Upgrade directives",
    "text": "Upgrade directives\nnbdev has slightly changed how “directive comments” like export and default_exp work, in order to align with how Quarto does things. Now, instead of just adding a # to the start to indicate a directive (e.g #export), you now need to use #| (e.g #|export). You can also optionally add a space (e.g #| export).\nTo automatically upgrade your directives to the new format, run in the root of your repo:\nnbdev_migrate\nYou should now test that you can export your module by running:\nnbdev_export\nNote that nbdev_export replaces nbdev_build_lib. Run nbdev_export -h to see the options you can pass to it (normally you won’t need to pass any). To see a list of all the commands available in nbdev2, run nbdev_help."
  },
  {
    "objectID": "migrating.html#add-and-remove-files",
    "href": "migrating.html#add-and-remove-files",
    "title": "nbdev1 migration",
    "section": "Add and remove files",
    "text": "Add and remove files\nFirst set a variable with the name of your library, by running the following (replacing “yourlib” with the name of your library’s subdirectory)\nexport LIBNAME=yourlib\nNow run the following:\ngit rm Makefile\ngit add $LIBNAME/_modidx.py\nrm -rf docs\nrm -f .gitconfig \nrm -f .git/hooks/post-merge\n\nrm -f setup.py\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/styles.css\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/setup.py\n\ncat >>.gitignore <<EOF\n_docs/\nsidebar.yml\nEOF\nAs you see above, we’ve remove the Makefile – that’s because all the things done by make before are now handled by nbdev commands directly.\n\n\n\n\n\n\nNote\n\n\n\nAll documentation related files should be included in your nbs_path, and all paths should be relative to it. If you have set the nbs_path in your settings.ini file, then copy your styles.css file inside of your nbs_path folder.\n\n\nIf you use GitHub Actions for continuous integration (CI) you can update this to use nbdev too as follows:\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/test.yaml\nmv test.yaml .github/workflows/"
  },
  {
    "objectID": "migrating.html#update-directive-names",
    "href": "migrating.html#update-directive-names",
    "title": "nbdev1 migration",
    "section": "Update directive names",
    "text": "Update directive names\nA number of directives have changed names. We’ll use perl to fix them. Run these lines in the root of your repo:\n[[ $SHELL = *bash ]] && shopt -s globstar\n\nperl -pi -e 's/#\\|\\s*hide_input/#| echo: false/' **/*.ipynb\nperl -pi -e 's/#\\|\\s*hide_output/#| output: false/' **/*.ipynb\nperl -pi -e 's/#\\|\\s*skip/#| eval: false/' **/*.ipynb\nperl -pi -e 's/from nbdev.export import notebook2script/from nbdev import nbdev_export/' **/*.ipynb\nperl -pi -e 's/notebook2script/nbdev_export/' **/*.ipynb\nThese change the following directives to use functionality built into Quarto:\n\nhide_input –> echo: false\nhide_output –> output: false\nskip –> eval: false\n\nThey also update the new location and name of the nbdev_export python function.\nIf you have any notebooks that you’ve asked nbdev1 to skip (using all_slow), you’ll need to add a raw cell to the top of your notebook containing YAML frontmatter. The frontmatter needs to include skip_showdoc: true to avoid running cells when rendering docs, and skip_exec: true to skip this notebook when running tests. E.g to do both, you would add a raw cell (or update your existing frontmatter raw cell) to contain:\n---\nskip_showdoc: true\nskip_exec: true\n---"
  },
  {
    "objectID": "migrating.html#final-steps",
    "href": "migrating.html#final-steps",
    "title": "nbdev1 migration",
    "section": "Final steps",
    "text": "Final steps\nYou should now edit settings.ini, and change doc_path from docs to _docs, since that’s where nbdev2 will build your website.\nIf you use a custom domain for your website, you should move your CNAME file into the directory containing your notebooks.\nBefore pushing to GitHub, check that your website looks OK locally by running:\nnbdev_preview\nNow prepare to commit to GitHub:\nnbdev_prepare\nYou can now commit to GitHub as usual. Finally, update Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set “Source” to gh-pages branch and the /root folder."
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Click through to any of these tutorials to get started with nbdev’s features.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nEnd-to-end walkthrough\n\n\nA step-by-step guide to using nbdev\n\n\n\n\nNotebook best practices\n\n\nHow to write great nbdev notebooks\n\n\n\n\nQmd documents\n\n\n\n\n\n\n\nRenderScripts\n\n\n\n\n\n\n\nGit-friendly Jupyter\n\n\nHow to use nbdev hooks for git-friendly Jupyter notebooks\n\n\n\n\nModular nbdev\n\n\nHow to use nbdev’s various tools separately\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tutorials/qmd_intro.html",
    "href": "tutorials/qmd_intro.html",
    "title": "Qmd documents",
    "section": "",
    "text": "Qmd documents are Markdown documents, but with loads of extra functionality provided by Quarto and Pandoc. nbdev uses Quarto to render its pages (with some extra functionality), and Quarto uses Pandoc to render its pages (with some extra functionality). Every markdown cell in an nbdev notebook is treated as qmd, and nbdev can publish plain qmd text files, and qmd RenderScripts. Therefore, it’s a good idea to be familiar with the main features of qmd.\nJust like with RenderScripts, you can use hot/live reloading with plain qmd text files – so as soon as you save the file, you’ll see the new output in your web browser (assuming you’ve got nbdev_preview running)."
  },
  {
    "objectID": "tutorials/qmd_intro.html#computations",
    "href": "tutorials/qmd_intro.html#computations",
    "title": "Qmd documents",
    "section": "Computations",
    "text": "Computations\nYou can generate data-driven documents using qmd files. For instance, consider this table (also shown in the RenderScript tutorial for comparison), containing a list of the people with testimonials on nbdev’s home page:\n\n\n\n\n\n\n\n\n\nName\nPosition\n\n\n\n\n\nChris Lattner\nInventor of Swift and LLVM\n\n\n\nFernando Pérez\nCreator of Jupyter\n\n\n\nDavid Berg\nSoftware Engineer, Netflix\n\n\n\nErik Gaasedelen\nSoftware Engineer, Lyft\n\n\n\nRoxanna Pourzand\nProduct Manager, Transform\n\n\n\nHugo Bowne-Anderson\nHead of Developer Relations, Outerbounds\n\n\n\nThe table above is generated using an embedded qmd computation block from the following python list:\n\ntestimonials = [\n    ('chris-lattner.png', 'Chris Lattner', 'Inventor of Swift and LLVM'),\n    ('fernando-pérez.jpeg', 'Fernando Pérez', 'Creator of Jupyter'),\n    ('david-berg.jpeg', 'David Berg', 'Software Engineer, Netflix'),\n    ('erik-gaasedelen.jpeg', 'Erik Gaasedelen', 'Software Engineer, Lyft'),\n    ('roxanna-pourzand.jpeg', 'Roxanna Pourzand', 'Product Manager, Transform'),\n    ('hugo-bowne-anderson.jpeg', 'Hugo Bowne-Anderson', 'Head of Developer Relations, Outerbounds')\n]\n\nJust like in the RenderScript example, to produce the table from this python list, the following four lines of code are used:\nprint(qmd.tbl_row(['','Name','Position']))\nprint(qmd.tbl_sep([1,3,4]))\nfor fname,name,position in testimonials:\n    print(qmd.tbl_row([im(fname, 60), name, position]))\nFor data-driven documents such as this one, we add the following to the YAML frontmatter, which hides the code used to produce outputs, and also does not add any extra formatting to outputs:\n---\nexecute:\n  echo: false\n  output: asis\n---\nCompare the source code of the RenderScript example and of the current page to see how computations are used in RenderScripts compared to plain qmd text files. We find that we like to use Notebooks for most pages we build, since they’ve got so much helpful functionality (such as pasting images directly into cells). We use RenderScripts for complex web pages like the nbdev home page, and qmd files for pages that are mainly markdown and don’t need any notebook functionality."
  },
  {
    "objectID": "tutorials/qmd_intro.html#formatting",
    "href": "tutorials/qmd_intro.html#formatting",
    "title": "Qmd documents",
    "section": "Formatting",
    "text": "Formatting\nIn addition to the standard markdown formatting, Quarto qmd adds many additional features. Look at the full quarto docs to see everything it can do – we’ll just highlight a few of our favorites here.\n\nDivs and classes\nYou can create HTML divs, by surrounding lines with :::. Divs can include classes by placing {.classname} after the opening :::. Here’s an example:\n::: {.border}\nThis content can be styled with a border\n:::\nThis is how that’s rendered:\n\nThis content can be styled with a border\n\nYou might be wondering where that border class comes from… Quarto comes with support for Bootstrap 5 and Bootswatch themes so there’s lots of classes available you can use in your documents. Remember, all notebook markdown cells are also considered qmd, and can also use all the formatting tricks discussed in this section.\n\n\nCallouts\nA special kind of block you can use is the callout block. Here’s an example:\n:::{.callout-note}\nNote that there are five types of callouts, including:\n`note`, `warning`, `important`, `tip`, and `caution`.\n:::\n…and here’s how it’s rendered:\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\nImages\nYou can add images (quarto calls them figures to your document, along with captions, and you can even arrange them into layouts. Here’s an example:\n::: {layout-ncol=3}\n![Jupyter](/images/jupyter.svg)\n\n![Vscode](/images/vscode.svg)\n\n![Git](/images/git.svg)\n:::\n\n\n\n\n\n\nJupyter\n\n\n\n\n\n\n\nVscode\n\n\n\n\n\n\n\nGit"
  },
  {
    "objectID": "tutorials/best_practices.html",
    "href": "tutorials/best_practices.html",
    "title": "Notebook best practices",
    "section": "",
    "text": "The flexibility offered by notebook development can be overwhelming. You might have grown comfortable with well-defined standards like numpy and sphinx docstrings which weren’t designed for notebooks. In this page, we’ll guide you through practices that we’ve found to improve the notebooks we develop.\nWe’re always open to improving our workflows, and don’t like to be too prescriptive about style. Please feel free to contribute your ideas in the forum."
  },
  {
    "objectID": "tutorials/best_practices.html#example-numpy-docstring-vs-nbdev",
    "href": "tutorials/best_practices.html#example-numpy-docstring-vs-nbdev",
    "title": "Notebook best practices",
    "section": "Example: numpy docstring vs nbdev",
    "text": "Example: numpy docstring vs nbdev\nIn this section, we’ll compare the numpy docstring format to our approach with nbdev, using the numpy.all function to demonstrate.\nExpand the code section below to see how numpy.all is defined and documented using the numpy docstring format.\n\n\nCode\ndef all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):\n    \"\"\"\n    Test whether all array elements along a given axis evaluate to True.\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a logical AND reduction is performed.\n        The default (``axis=None``) is to perform a logical AND over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n        .. versionadded:: 1.7.0\n        If this is a tuple of ints, a reduction is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternate output array in which to place the result.\n        It must have the same shape as the expected output and its\n        type is preserved (e.g., if ``dtype(out)`` is float, the result\n        will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more\n        details.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `all` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n    where : array_like of bool, optional\n        Elements to include in checking for all `True` values.\n        See `~numpy.ufunc.reduce` for details.\n        .. versionadded:: 1.20.0\n    Returns\n    -------\n    all : ndarray, bool\n        A new boolean or array is returned unless `out` is specified,\n        in which case a reference to `out` is returned.\n    See Also\n    --------\n    ndarray.all : equivalent method\n    any : Test whether any element along a given axis evaluates to True.\n    Notes\n    -----\n    Not a Number (NaN), positive infinity and negative infinity\n    evaluate to `True` because these are not equal to zero.\n    Examples\n    --------\n    >>> np.all([[True,False],[True,True]])\n    False\n    >>> np.all([[True,False],[True,True]], axis=0)\n    array([ True, False])\n    >>> np.all([-1, 4, 5])\n    True\n    >>> np.all([1.0, np.nan])\n    True\n    >>> np.all([[True, True], [False, True]], where=[[True], [False]])\n    True\n    >>> o=np.array(False)\n    >>> z=np.all([-1, 4, 5], out=o)\n    >>> id(z), id(o), z\n    (28293632, 28293632, array(True)) # may vary\n    \"\"\"\n    pass\n\n\nHere is how we’d define, document, and test it in a notebook using nbdev, with additional commentary in the margin on the right.\n#| export\ndef all(a, # Input array or object that can be converted to an array.\n        axis:int|tuple|None=None, # Axis or axes along which a logical AND reduction is performed (default: all).\n        out:np.ndarray|None=None, # Alternate output array in which to place the result.\n        keepdims:bool=np._NoValue, # If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n        where=np._NoValue, # Elements to include in checking for all `True` values. See `numpy.ufunc.reduce` for details. New in version 1.20.0.\n        ) -> np.ndarray|bool: # A new boolean or array is returned unless `out` is specified, in which case a reference to `out` is returned.\n    \"Test whether all array elements along a given axis evaluate to `True`.\"\n    pass\n\n\nStart by defining your function.  Our definition uses simple type annotations which get rendered in the function’s parameters table.  The comment after each parameter is called docments – a concise alternative to numpy and sphinx docstring formats (see the docments section for more).  Note that we’ve left out some parts of the parameter docs from numpy’s docstring, and that the function docstring is only a single line. We prefer to keep docstrings short and instead elaborate in separate cells below, where we can use markdown and real code examples. \n\n\n\nall\n\n all (a, axis:Union[int,tuple,NoneType]=None,\n      out:Optional[numpy.ndarray]=None, keepdims:bool=<no value>,\n      where=<no value>)\n\nTest whether all array elements along a given axis evaluate to True.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\nInput array or object that can be converted to an array.\n\n\naxis\nint | tuple | None\nNone\nAxis or axes along which a logical AND reduction is performed (default: all).\n\n\nout\nnp.ndarray | None\nNone\nAlternate output array in which to place the result.\n\n\nkeepdims\nbool\n\nIf this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n\n\nwhere\n_NoValueType\n\nElements to include in checking for all True values. See numpy.ufunc.reduce for details. New in version 1.20.0.\n\n\nReturns\nnp.ndarray | bool\n\nA new boolean or array is returned unless out is specified, in which case a reference to out is returned.\n\n\n\n\n\n\n\nOur function definition is automatically rendered in the docs like this. Note that parameter names, types, defaults, and details are all parsed from the definition and included here.\nFor example:\n\n\nNext, describe how to use your function using markdown cells and lots of code examples. This is the biggest benefit to developing in notebooks: instead of copying and pasting code examples into plaintext, you can include real executeable code examples.  We start with basic usage first, then elaborate on more advanced functionality for each parameter. This differs from numpy’s approach which included all parameter docs in the table and where not all parameters included code examples.  Our code examples use assertion functions from fastcore.test, so that they serve as both docs and tests. nbdev_test runs every code cell as a test (unless it’s explicitly marked otherwise), and any error in the cell fails the test.\n\nx = [[True,False],[True,True]]\ntest_eq(np.all(x), False)\n\nWith axis:\n\ntest_eq(np.all(x, axis=0), [True,False])\n\naxis may be negative, in which case it counts from the last to the first axis:\n\ntest_eq(np.all(x, axis=-1), [False,True])\n\nIf axis is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before.\n\ntest_eq(np.all(x, axis=(0,1)), False)\n\nIntegers, floats, not a number (nan), and infinity all evaluate to True because they’re not equal to zero:\n\ntest_eq(np.all([-1, 1, -1.0, 1.0, np.nan, np.inf, -np.inf]), True)\n\nYou can use where to test specific elements. For example, this tests only the second column:\n\ntest_eq(np.all(x, where=[[False],[True]]), True)\n\nThe output can be stored in an optional out array. If provided, a reference to out will be returned:\n\no = np.array(False)\nz = np.all([-1, 4, 5], out=o)\ntest_is(z, o)\ntest_eq(z, True)\n\nout must have the same shape as the expected output and its type is preserved (e.g., if dtype(out) is float, the result will consist of 0.0’s and 1.0’s). See Output type determination for more details.\nWith keepdims, the result will broadcast correctly against the input array.\n\ntest_eq(np.all(x, axis=0, keepdims=True), [[True, False]]) # Note the nested list\n\nIf the default value is passed, then keepdims will not be passed through to the all method of sub-classes of ndarray, however any non-default value will be. If the sub-class’ method does not implement keepdims any exceptions will be raised.\n\nclass MyArray(np.ndarray):\n    def all(self, axis=None, out=None): pass\n\ny = MyArray((2,2))\ny[:] = x\nnp.all(y) # No TypeError since `keepdims` isn't passed\ntest_fail(lambda: np.all(y, keepdims=True), contains=\"all() got an unexpected keyword argument 'keepdims'\")\n\n\n\nSince we prefer to document via code examples, we also document error-cases with assertions using fastcore.test.test_fail. This differs from docstring-based approaches which usually document error-cases in prose, usually in a “raises” section of the docstring.\nThe numpy.ndarray.all method is equivalent to calling numpy.all with the array:\n\n\nWe link to related symbols with doclinks: symbols surrounded in backticks are automatically linked, and we describe their relation using code examples.\n\ntest_eq(np.array(x).all(), np.all(x))\n\nIn contrast, numpy.any tests whether any element evaluates to True (rather than all elements):\n\ntest_eq(np.any(x), True)\n\n\nRecap\nIn summary, here is how the nbdev version of numpy.all differs from the numpy docstring. ndev uses:\n\nType annotations and docments instead of the numpy docstring format (although nbdev supports numpy docstrings too)\nShort parameter descriptions, with details in separate cells with markdown and code example\nDoclinks to related symbols instead of a “See also” section\nLots of code examples (which are also tests) mixed with prose to describe how to use the function\nCode examples with assertions to document error-cases instead of a “Raises” section."
  },
  {
    "objectID": "tutorials/best_practices.html#general-principles",
    "href": "tutorials/best_practices.html#general-principles",
    "title": "Notebook best practices",
    "section": "General principles",
    "text": "General principles\nNow that we’ve walked through a full example, let’s considers the general principles underlying the decisions we made.\n\nKnow which form of notebook you’re writing\nFirst of all, decide which form of notebook you’re writing. We’re fans of the divio system which classifies documentation into four forms: tutorials, how-to guides, explanations, and references. They’ve laid this out beautifully in the following diagram:\n\n\n\nStart with a great title and subtitle\nStart with a markdown cell at the top of your notebook with its title in an H1 header, and subtitle in a blockquote. For example:\n# Great title\n\n> And an even better subtitle\nThe title will also be used to reference your page in the sidebar. You can also optionally add frontmatter to this cell to customize nbdev and Quarto.\n\n\nIntroduce your notebook\nIntroduce your notebook with markdown cells below the title. We recommend a slightly different approach depending on the form of documentation:\n\nReference: Start with a brief description of the technical component, and an overview that links to the main symbols in the page (you might want to use doclinks)\nTutorials and how-to guides: Describe what the reader will learn and how. Keep it short and get to the subject matter quickly\nExplanations: Since these are typically very focused, a short description of the topic is often sufficient.\n\n\n\nUse lots of code examples, pictures, plots, and videos\nTake advantage of the richness of notebooks by including code examples, pictures, plots, and videos.\nHere are a few examples to get you started:\n\nfastai’s documentation makes extensive use of code examples, plots, images, and tables, for example, the computer vision intro\nnbdev.release opens with a terminal screencast demo in SVG format created with asciinema and svg-term-cli\nThe documentation explanation describes a complex data pipeline using a Mermaid diagram\nThe directives explanation showcases all of nbdev’s directives with executable examples in call-out cards (and makes great use of emojis too!)\nRDKit renders beautiful molecule diagrams\n\n\n\nKeep docstrings short; elaborate in separate cells\nWhile nbdev renders docstrings as markdown, they aren’t rendered correctly when using symbol? or help(symbol) and they can’t include executed code. By splitting longer docstrings across separate code and markdown cells you can use code examples, pictures, plots, and videos.\nWe find a single-line summary sufficient for most docstrings.\n\n\nDocument parameters with docments\nfastcore.docments is a concise way to document parameters that is beautifully rendered by nbdev. For example, this function:\n\ndef draw_n(n:int, # Number of cards to draw\n           replace:bool=True # Draw with replacement?\n          )->list: # List of cards\n    \"Draw `n` cards.\"\n\n…would include the following table as part of its documentation:\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n\nNumber of cards to draw\n\n\nreplace\nbool\nTrue\nDraw with replacement?\n\n\nReturns\nlist\n\nList of cards\n\n\n\n\nnbdev also supports some numpy docstring sections. For example, this code snippet would produce the same table (there’s no need to include types like in the docstring if you already have annotations):\n\ndef draw_n(n:int, replace:bool=True) -> Cards:\n    \"\"\"\n    Draw `n` cards.\n    \n    Parameters\n    ----------\n    n\n        Number of cards to draw\n    replace\n        Draw with replacement?\n        \n    Returns\n    -------\n    cards\n        List of cards\n    \"\"\"\n\n\n\n\n\n\n\nYou can render a symbol’s parameters table directly with DocmentTbl. In fact, that’s how we rendered the table above.\n\n\n\n\n\nConsider turning code examples into tests by adding assertions\nnbdev blurs the lines between code, docs, and tests. Every code cell is run as a test (unless it’s explicitly marked otherwise), and any error in the cell fails the test.\nConsider turning your code examples into tests by adding assertions – if they would make valuable tests and if it doesn’t hurt readability. fastcore.test provides a set of light wrappers around assert for better notebook tests (for example, they print both objects on error if they differ).\nHere’s an example using fastcore.test.test_eq:\n\ndef inc(x): return x + 1\ntest_eq(inc(3), 4)\n\n\n\nDocument error-cases as tests\nDocstring-driven approaches typically document the errors raised by an object using plaintext descriptions, for example, in a “raises” section.\nIn nbdev, we recommend documenting errors with actual failing code using fastcore.test.test_fail. For example:\n\ndef divide(x, y): return x / y\ntest_fail(lambda: divide(1, 0), contains=\"division by zero\")\n\nThe first argument is a lambda since we need to allow test_fail to control its execution and catch any errors.\n\n\nReference related symbols with doclinks\nIf you surround a symbol with backticks, nbdev will automatically link to that symbol’s reference page. We call these doclinks.\nPrefer fully qualified symbol paths, like package.module.symbol instead of symbol. It may be more verbose but it helps users know which module a symbol originates from, which is especially important for third-party packages.\nAny package created with nbdev will automatically support doclinks. Non-nbdev packages can be supported by creating a minimal nbdev-index package. nbdev-index is a collection of such packages, which already supports django, numpy, pandas, pytorch, scipy, sphinx, the Python standard library, and even other programming languages like APL!\n\n\nAdd rich representations to your classes\nThis is another way to take advantage of the rich display feature of notebooks. You can provide rich representations to your object by defining a _repr_markdown_ method that returns markdown text (which may also include HTML/CSS).\nHere’s a simple example to get you started:\n\nclass Color:\n    def __init__(self, color): self.color = color\n    def _repr_markdown_(self):\n        style = f'background-color: {self.color}; width: 50px; height: 50px; margin: 10px'\n        return f'<div style=\"{style}\"></div>'\n\n\nColor('green')\n\n\n\n\n\n\n\nColor('blue')\n\n\n\n\n\n\nAlso see the earlier list of example projects that make use of beautiful visual representations.\n\n\nDocument class methods with show_doc or fastcore.basics.patch\nnbdev automatically documents exported function and class definitions with show_doc. However, it’s up to you to document class methods. There are two ways to do that: calling show_doc on the method, or defining the method with the fastcore.basics.patch decorator.\n\nNotebook (show_doc)Notebook (@patch)Docs\n\n\nIf your class is defined in a single cell, use show_doc. Here’s what your notebook might look like:\n\n#| export\nclass Number:\n    \"A number.\"\n    def __init__(self, num): self.num = num\n    def __add__(self, other):\n        \"Sum of this and `other`.\"\n        return Number(self.num + other.num)\n    def __repr__(self): return f'Number({self.num})'\nFor example, here is the number 5:\nNumber(5)\nshow_doc(Number.__add__)\nFor example:\nNumber(3) + Number(4)\n\n\n\nIf you split your class definition across cells with fastcore.basics.patch, here’s what your notebook might look like:\n\n#| export\nclass Number:\n    \"A number.\"\n    def __init__(self, num): self.num = num\n    def __repr__(self): return f'Number({self.num})'\nFor example, here is the number 5:\nNumber(5)\n#| export\n@patch\ndef __add__(self:Number, other):\n    \"Sum of this and `other`.\"\n    return Number(self.num + other.num)\nFor example:\nNumber(3) + Number(4)\n\n\n\nIn either case, this is how the documentation would be rendered:\n\n\n\nNumber\n\n Number (num)\n\nA number.\nFor example, here is the number 5:\n\nNumber(5)\n\nNumber(5)\n\n\n\n\n\nNumber.__add__\n\n Number.__add__ (other)\n\nSum of this and other.\nFor example:\n\nNumber(3) + Number(4)\n\nNumber(7)\n\n\n\n\n\n\n\n\n\nGroup symbols with H2 sections\nAs your notebooks grow, consider grouping related symbols using markdown cells with level 2 headers. Since nbdev displays documented symbols as level 3 headers, this would group all symbols below your level 2 header.\nHere is the markdown syntax:\n## Section title\n\n\nSplit long explanations with H4 sections\nSimilar to the previous section, as a symbol’s explanation grows, consider grouping its cells using level 4 headers. This is the recommended way to structure your reference docs, for example, to achieve numpy-style structures with sections like notes, examples, methods, and so on.\nHere’s the markdown syntax:\n#### Section title"
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html",
    "href": "tutorials/git_friendly_jupyter.html",
    "title": "Git-friendly Jupyter",
    "section": "",
    "text": "Version control is essential to developing software, yet Jupyer notebooks don’t work with version control by default. nbdev solves this problem! It provides a set of hooks which enable git-friendly Jupyter notebooks in any git repo, including those that don’t use the broader nbdev system.\nTo get started, install nbdev:\nthen install hooks:\nThat’s it! Read on if you’re stuck or if you’d like to learn more about nbdev hooks and how to customise them."
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html#quickstart-install-nbdev-hooks-for-a-repo",
    "href": "tutorials/git_friendly_jupyter.html#quickstart-install-nbdev-hooks-for-a-repo",
    "title": "Git-friendly Jupyter",
    "section": "Quickstart: Install nbdev hooks for a repo",
    "text": "Quickstart: Install nbdev hooks for a repo\nTo start with, change directory to your current project and double-check. Don’t worry about the strange path, that’s because we’re using a temporary directory for this tutorial:\n\n!pwd\n\n/private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmp15d4zvbi/repo\n\n\nInstall nbdev:\n\n!pip install -Uqq nbdev\n\nInstall nbdev hooks:\n\n!nbdev_install_hooks\n\nNot in a git repository, git hooks cannot be installed.\n\n\nYou’ll see the above error if you’re not in a git repo. If so, initialise a git repository:\n\n!git init\n\nInitialized empty Git repository in /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmp15d4zvbi/repo/.git/\n\n\nThen try installing nbdev hooks again:\n\n!nbdev_install_hooks\n\nHooks are installed.\n\n\nIf you already have a pre-save hook set in your Jupyter config file we won’t be able to safely install a new one automatically. Instead, you’ll encounter an error and will need to follow its instructions for a manual installation.\nJupyter hooks will now be installed in your user’s Jupyter config directory, and will work for all repos by default. Git hooks will only be installed in the current repo; you will need to rerun nbdev_install_hooks for each of your git repos. See Configuring nbdev hooks if you’d like to customise hook behaviour, for example, to opt out of hooks in certain repos."
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html#what-are-nbdev-hooks",
    "href": "tutorials/git_friendly_jupyter.html#what-are-nbdev-hooks",
    "title": "Git-friendly Jupyter",
    "section": "What are nbdev hooks?",
    "text": "What are nbdev hooks?\nnbdev provides three hooks to ease Jupyter-git integration.\n\nnbdev_merge on merging notebooks with git\nOne of the biggest complaints when working with Jupyter is that merge conflicts break notebooks. This is particularly problematic in projects with many collaborators.\n\n\n\nJupyter notebook shows the above error when opening a notebook with merge conflicts.\n\n\nOftentimes these conflicts are on metadata like cell execution counts that we don’t really care about. nbdev comes with a custom git merge driver that automatically fixes conflicting outputs and metadata, and that leaves remaining conflicts in a state that still works with Jupyter. It works in all git commands that use merge under the hood, including merge, pull, rebase, and stash.\nHere’s what the conflict looks like in Jupyter with nbdev’s merge driver:\n\n\n\n\n\n\n\nnbdev_clean on saving notebooks in Jupyter\nJupyter notebooks store a variety of metadata (including execution counts and notebook extension info) that aren’t conducive to collaborative version control systems like git. These pollute diffs in pull requests and git histories (which can make debugging harder), and tend to cause merge conflicts. For example:\n  {\n   \"cell_type\": \"code\",\n-  \"execution_count\": 1,\n+  \"execution_count\": 2,\n   \"metadata\": {\n     \"hide_input\": false\n  }\nPython’s default repr is another example, since it includes a memory address which we usually aren’t interested in:\n-<matplotlib.axes._subplots.AxesSubplot at 0x7fbc11508950>\n+<matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90>\nnbdev install a Jupyter hook which runs nbdev_clean to automatically clean unwanted metadata and outputs from your notebooks, including ids from default Python reprs! With nbdev hooks, the examples above would become:\n{\n  \"cell_type\": \"code\",\n  \"execution_count\": null,\n  \"metadata\": {}\n}\nand\n<matplotlib.axes._subplots.AxesSubplot>\n\n\nnbdev_trust after merging notebooks with git\nA side-effect of Jupyter’s security model is that widgets don’t work in collaborative repos, unless you manually “trust” notebooks after each git pull. There is a good reason behind this: since Jupyter notebooks contain HTML and JavaScript, the trust system avoids running malicious code when you open a notebook and don’t explicitly run any cells. See the official documentation for more.\nManually trusting notebooks each time is a pain. A more natural workflow would be trust a repo once-off, and all notebooks and changes thereafter. nbdev includes a git post-merge hook which runs nbdev_trust in your repo to do exactly this."
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html#configuring-nbdev-hooks",
    "href": "tutorials/git_friendly_jupyter.html#configuring-nbdev-hooks",
    "title": "Git-friendly Jupyter",
    "section": "Configuring nbdev hooks",
    "text": "Configuring nbdev hooks\nThe most up-to-date reference of nbdev’s settings is in the nbdev_create_config docs. In addition, this section will guide you through a few common configurations.\nControl whether Jupyter hooks are run:\n\nGlobally enable Jupyter hooks: set jupyter_hooks = True in user settings\nGlobally disable Jupyter hooks: set jupyter_hooks = False in user settings (at ~/.config/nbdev/settings.ini)\nEnable Jupyter hooks only for selected repos: set jupyter_hooks = False in user settings and jupyter_hooks = True in selected repo settings\n\nCustomise notebook cleaning with the following settings:\n\nClean all outputs and metadata: clear_all\nPreserve certain metadata by key: allowed_metadata_keys and allowed_cell_metadata_keys\nClean ids from default Python reprs: clean_ids\n\nAll of the above can be customised per-user and per-repo.\nControl whether git hooks are run:\nSince git hooks are installed per-repo they’ll only run in repos where you manually nbdev_install_hooks. If you change your mind later, you can uninstall git hooks by following the instructions in the .gitconfig file created in your repo."
  },
  {
    "objectID": "tutorials/tutorial.html",
    "href": "tutorials/tutorial.html",
    "title": "End-to-end walkthrough",
    "section": "",
    "text": "The written tutorial below shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:"
  },
  {
    "objectID": "tutorials/tutorial.html#installation",
    "href": "tutorials/tutorial.html#installation",
    "title": "End-to-end walkthrough",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\n\nInstall Jupyter Notebook\nLaunch a terminal and install Jupyter Notebook by entering:\nconda install notebook\n…or\npip install notebook\n…if you’re using the pip package manager.\nEnter y (for yes) if prompted. Installation should take a few seconds, during which text will be printed in the terminal. You’ll know its completed when you see the terminal prompt and are able to type again.\nYou can now launch Jupyter by entering:\njupyter notebook\nThis should open the Jupyter home page in a new browser tab:\n\n\n\n\n\n\n\n\n\n\n\nWhy not Jupyter Lab?\n\n\n\n\n\nAs Jupyter power users we still prefer Jupyter Notebook (with customizations) over more feature-full alternatives like Jupyter Lab, VSCode, or PyCharm. We find Jupyter Notebook simpler, faster, and more robust.\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. Jupyter Notebook comes with its own terminal, so we’ll use that moving forward.\nIn the Jupyter home page (shown in the previous section), click the “New” dropdown on the right side, then “Terminal”.\nA browser tab should open with a blank terminal:\n\n\n\n\n\nEnter:\nconda install -c fastai nbdev\n…or\npip install nbdev\n…if you’re using pip.\nType y (for yes) when prompted, and wait a few seconds until nbdev is installed.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions."
  },
  {
    "objectID": "tutorials/tutorial.html#first-steps",
    "href": "tutorials/tutorial.html#first-steps",
    "title": "End-to-end walkthrough",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license file just yet.\nIf you’re using the web interface, it should look something like this before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the GitHub CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda.\nConfigure Quarto for publication-grade technical documentation.\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages.\n\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\n\n\n\n\n\nNote\n\n\n\nnbdev_new assumes that your package name is the same as your repo name (with - replaced by _). Use the --lib_name option if that isn’t the case.\n\n\nDouble-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\nIt’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green check (✅) because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nIf you see a red cross (❌), that means something failed. Click on the cross, then click Details, and you’ll be able to see what failed. If you can’t figure out what’s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we’ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what’s wrong.\nWhat do these workflows do?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nWe provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking.\nNote that you’ll need to enable GitHub Pages for your repo before you can access your docs website. We’ll do that now.\n\n\nCheck out your docs\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\n\nEnabling GitHub Pages\n\n\n\n\n\n\nEnabling GitHub Pages Is Not Required For Everyone\n\n\n\nnbdev makes a best effort to automatically enable GitHub Pages for you, however, there some cases where this is not possible such as private repos or where your organization’s permissions are restricted. If you are having trouble seeing your site, we suggest checking if Pages are enabled for your repo by following the below instructions.\nYou can enable it for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\nIt should look similar to this after you click “Save”:\n\n\n\n\n\n\n\nHead back to GitHub Actions and you should see a new workflow run: “pages build and deployment”. As the name says, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible. However, you can use any host you like. See these docs for more information on this.\n\n\n\n\n\nRecap\nYou now have a base nbdev repo with continuous integration and hosted documentation! Here’s a recap of the steps you took:\n\nCreated a GitHub repo\nInitialised your repo with nbdev_new\nPushed to GitHub."
  },
  {
    "objectID": "tutorials/tutorial.html#make-your-first-edit",
    "href": "tutorials/tutorial.html#make-your-first-edit",
    "title": "End-to-end walkthrough",
    "section": "Make your first edit",
    "text": "Make your first edit\nIn this section, you’ll make your first edit to the repo you created in First steps.\n\nInstall hooks for git-friendly notebooks\nStep one when working with Jupyter notebooks in a new repo is to install nbdev’s hooks (you can think of “hooks” as plugins or extensions to an application).\nInstall them by entering this command in your terminal:\nnbdev_install_hooks\nSee Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here’s a short summary:\n\nFix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter.\nEach time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts.\nAutomatically trust notebooks in the repo so that you can view widgets from collaborators’ commits. For this reason, you should not install hooks into a repo you don’t trust.\n\n\n\n\n\n\n\nTip\n\n\n\nnbdev hooks works on any git repo, even if it doesn’t use the broader nbdev system.\n\n\n\n\nBuild your library\nYou should now create your package from your notebook by running:\nnbdev_export\nThis will create Python modules for your notebooks. These modules will make up the contents of your Python package.\n\n\nInstall your package\nYou might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package.\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package during development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\n\n\nPreview your docs\nnbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks.\nStart the preview by entering this into your terminal:\nnbdev_preview\nIt may say Preparing to preview for a few seconds while it gets started, and will eventually display something like:\nWatching files for changes\nBrowse at http://localhost:3000/\nClick the link to open the preview in a new browser tab. It should look exactly like your online docs.\n\n\n\n\n\n\nTip\n\n\n\nWe often find it useful to keep a preview window open on the side while we’re editing our notebooks in Jupyter.\n\n\n\n\nEdit 00_core.ipynb\nNow, run jupyter notebook, and click 00_core.ipynb. You don’t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in – even though it could have been created in a different order.\n\nAdd your own frontmatter\nYou’ll see something that looks a bit like this:\n\ncore\n\nFill in a module description here\n\n#| default_exp core\n\nLet’s explain what these special cells means:\n\nThe first is a markdown cell with nbdev’s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains:\n\nH1 header (“core”) – defining the page title\nQuote (“Fill in a module description here”) – defining the page description\n\nThe second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module.\n\nNext, rename the notebook, replace the title and description, and change the default export module for your own project.\nOnce you’re done, save the notebook. The live preview started in the previous section should update with your latest changes.\nRerun all cells in your notebook to ensure that they work, and to export the updated modules.\n\n\n\n\n\n\nTip\n\n\n\nWe find the “restart kernel and run all cells” Jupyter command (the ⏩ button) so invaluable that we bind it to a keyboard shortcut. A common criticism of notebooks is that out-of-order execution leads to irreproducible notebooks. In our experience, making “restart and rerun” a habit solves this problem.\n\n\nRunning the notebook exports Python modules because of the last cell which contains:\n#| hide\nimport nbdev; nbdev.nbdev_export()\nWhat does this mean?\n\n#| hide is a directive (like #| default_exp) which excludes a cell from both your exported module and docs\nnbdev_export is the command used to export your notebooks to Python modules.\n\nWe recommend including a cell like this at the bottom of all of the notebooks you want to export.\n\n\n\n\n\n\nWarning\n\n\n\nRemember to delete any unused modules that aren’t exported by a notebook or otherwise needed by your package. This is likely to happen if you change the default export of a notebook – nbdev doesn’t remove the old module. This is intended, since nbdev is designed to work with hybrid packages that use .py modules (with no corresponding notebook) as well as those exported from notebooks.\n\n\n\n\nAdd your own function\nAdd a new code cell below the #| default_exp cell with a function. For example:\n#| export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #| export at the top – this is a directive (like #| default_exp) that tells nbdev to include the cell in your exported module and in your documentation.\nThe documentation should look like this:\n\n\nsource\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\n\nAdd your own examples, tests, and docs\nOne of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code.\nInclude regular code cells, and they’ll appear (with output) in your docs, for example:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\")==\"Hello Hamel!\"\n\n…or functions from fastcore.test, which behave like assert but also display the actual and expected values if they differ:\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nAnother superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here’s an SVG circle:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('<svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"50\" cy=\"50\" r=\"40\"/></svg>'))\n\n\n\n\n\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for Github\nnbdev_readme: Updates README.md from your index notebook.\n\n\n\nEdit index.ipynb\nNow you’re ready to create your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open the Jupyter Notebook home page, then click on index.ipynb to open it.\nWe recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text.\n\n\nPush to Github\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.\n\n\nRecap\nCongratulations, you’ve used all of the basics needed to build delightful projects with nbdev! Here’s a recap of the steps you took:\n\nInstalled hooks for git-friendly notebooks with nbdev_install_hooks\nInstalled your package with pip install -e '.[dev]'\nPreviewed your docs with nbdev_preview\nAdded your own frontmatter, function, tests, and docs to 00_core.ipynb\nPrepared your changes with nbdev_prepare\nUpdated index.ipynb with your own information\nPushed to GitHub.\n\nRead on to learn about more advanced nbdev functionality. Also see our Explanations in the sidebar on the left for deep-dives on specific topics."
  },
  {
    "objectID": "tutorials/tutorial.html#advanced-functionality",
    "href": "tutorials/tutorial.html#advanced-functionality",
    "title": "End-to-end walkthrough",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#| export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore>=1.0.5 torchvision<0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to\n\n\nUpload to pypi and conda\nThe command nbdev_release from the root of your nbdev repo will bump the version of your module and upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n$$\\sum_{i=1}^{k+1}i$$\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github.\n\n\nQuarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts:\n\n\n\n\nflowchart LR\n  A[Hard edge] --> B(Round edge)\n  B --> C{Decision}\n  C --> D[Result one]\n  C --> E[Result two]\n\n\n\n\n\n\n\n\nHere is another example of using Graphviz:\n\n\n\n\n\n\n\nG\n\n  \n\nrun\n\n run   \n\nintr\n\n intr   \n\nrun–intr\n\n   \n\nkernel\n\n kernel   \n\nrun–kernel\n\n   \n\nrunbl\n\n runbl   \n\nintr–runbl\n\n   \n\nrunbl–run\n\n   \n\nzombie\n\n zombie   \n\nkernel–zombie\n\n   \n\nsleep\n\n sleep   \n\nkernel–sleep\n\n   \n\nrunmem\n\n runmem   \n\nkernel–runmem\n\n   \n\nsleep–runmem\n\n   \n\nswap\n\n swap   \n\nsleep–swap\n\n   \n\nrunswap\n\n runswap   \n\nswap–runswap\n\n   \n\nrunswap–runmem\n\n   \n\nnew\n\n new   \n\nrunswap–new\n\n   \n\nnew–runmem\n\n  \n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered."
  },
  {
    "objectID": "tutorials/renderscript.html",
    "href": "tutorials/renderscript.html",
    "title": "RenderScripts",
    "section": "",
    "text": "RenderScripts are regular Python scripts, except that:\n\nRather than just having the extension .py, they have an extension like .qmd.py\nThey contain a module docstring containing frontmatter (i.e three hyphens on a line, then some yaml, then another three hyphens on a line).\n\nThese scripts are run when your site is rendered. Anything that they print to stdout becomes a new file in your site. The name of the file is the same as the name of the .py script, but without the .py extension. For instance, the page you’re reading right now page is created by a script called renderscript.qmd.py, which you’ll find here.\nHot/live reloading even works with these .py scripts – so as soon as you save the script, you’ll see the new output in your web browser.\nThis approach can be particularly helpful for generating data-driven documents. For instance, consider this table, containing a list of the people with testimonials on nbdev’s home page:\n\n\n\n\n\n\n\n\n\nName\nPosition\n\n\n\n\n\nChris Lattner\nInventor of Swift and LLVM\n\n\n\nFernando Pérez\nCreator of Jupyter\n\n\n\nDavid Berg\nSoftware Engineer, Netflix\n\n\n\nErik Gaasedelen\nSoftware Engineer, Lyft\n\n\n\nRoxanna Pourzand\nProduct Manager, Transform\n\n\n\nHugo Bowne-Anderson\nHead of Developer Relations, Outerbounds\n\n\n\nWhen creating a table like this, it can be tricky to ensure that markdown is correct and consistent for every row. It can be easier and more maintainable to programatically generate it. The table above is generated from the following python list:\n\ntestimonials = [\n    ('chris-lattner.png', 'Chris Lattner', 'Inventor of Swift and LLVM'),\n    ('fernando-pérez.jpeg', 'Fernando Pérez', 'Creator of Jupyter'),\n    ('david-berg.jpeg', 'David Berg', 'Software Engineer, Netflix'),\n    ('erik-gaasedelen.jpeg', 'Erik Gaasedelen', 'Software Engineer, Lyft'),\n    ('roxanna-pourzand.jpeg', 'Roxanna Pourzand', 'Product Manager, Transform'),\n    ('hugo-bowne-anderson.jpeg', 'Hugo Bowne-Anderson', 'Head of Developer Relations, Outerbounds')\n]\n\nTo produce the table from this python list, the following four lines of code are used:\nprint(qmd.tbl_row(['','Name','Position']))\nprint(qmd.tbl_sep([1,3,4]))\nfor fname,name,position in testimonials:\n    print(qmd.tbl_row([im(fname, 60), name, position]))\ntbl_hdr and tbl_row are two functions imported from the module nbdev.qmd. nbdev.qmd is a small module that has some convenient functions for creating .qmd documents, such as the table creation functions used above. You can see more examples of their use in index.qmd.py, which is the RenderScript which creates the nbdev home page. The nbdev home page is a more idiomatic example of how to use RenderScripts than the current page’s source code – we’re only using RenderScript for the current page to provide a more simple example. In practice, we find that RenderScripts are best used for pages containing a lot of data-driven content, reusable components, and so forth.\nYou can use RenderScripts to create any kind of file. For instance, the SVG below is created dynamically using this script:\n\nOnce you’ve run nbdev_preview or nbdev_docs you’ll find your rendered document in the _proc directory, along with all of your processed notebooks. This can be helpful for debugging. You can also simply call your script directly from the shell (e.g. python renderscript.qmd.py) to view the printed output."
  },
  {
    "objectID": "tutorials/modular_nbdev.html",
    "href": "tutorials/modular_nbdev.html",
    "title": "Modular nbdev",
    "section": "",
    "text": "While nbdev_new gets you started with everything you need to create a delightful Python package, you can also use each of nbdev’s components listed below on their own. You might find this useful if you’re porting a large system over to nbdev, or if you’d like to customise the nbdev workflow for your own project. Note that all of the commands below work without a settings.ini file.\n\nnbdev_test: Test notebooks\nYou can test an individual notebook with the terminal command:\nnbdev_test --path notebook.ipynb\n…or a folder of notebooks:\nnbdev_test --path tests/\n\n\nnb_export: Export notebooks to modules\nYou can export a notebook to a module with the Python function:\nnb_export('notebook.ipynb', 'pkg')\n…provided the notebook specifies a default_exp directive at the top, and export directives above each cell to be exported. We recommend including this in a code cell at the bottom of your notebook for convenience.\n\n\nnbdev_install_hooks: Improve Jupyter/git integration\nYou can install nbdev hooks into any git repo with the terminal command:\nnbdev_install_hooks\nOr directly use any of its underlying commands, for example, to implement your own hooks or extensions:\n\nnbdev_clean\nnbdev_fix\nnbdev_merge\nnbdev_trust\n\n\n\nnbdev.release: Easy packaging on PyPI, conda, and GitHub\nCheck out the nbdev.release docs for more. Note that this functionality requires a settings.ini file.\n\n\nnbdev.quarto: Technical documentation with Quarto\nCheck out the nbdev.quarto docs for more. Note that this functionality requires a settings.ini file."
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "NB: This is nbdev v2, a major upgrade of nbdev. Whilst the differences to nbdev1 aren’t huge, it does require some changes. The old version docs are at nbdev1.fast.ai. You can use version-pinning in settings.ini (i.e 'nbdev<2') to stop nbdev from upgrading. To upgrade, follow the migration tutorial.\nnbdev is a notebook-driven development platform. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free!\nnbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class."
  },
  {
    "objectID": "getting_started.html#install",
    "href": "getting_started.html#install",
    "title": "Getting started",
    "section": "Install",
    "text": "Install\nnbdev works on macOS, Linux, and most Unix-style operating systems. It works on Windows under WSL, but not under cmd or Powershell.\nYou can install nbdev with pip:\npip install nbdev\n… or with conda (or mamba):\nconda install -c fastai nbdev\nNote that nbdev must be installed into the same Python environment that you use for both Jupyter and your project."
  },
  {
    "objectID": "getting_started.html#how-to-use-nbdev",
    "href": "getting_started.html#how-to-use-nbdev",
    "title": "Getting started",
    "section": "How to use nbdev",
    "text": "How to use nbdev\nThe best way to learn how to use nbdev is to complete either the written walkthrough or video walkthrough:\n\n\n\n\nAlternatively, there’s a shortened version of the video walkthrough with coding sections sped up using the unsilence Python library – it’s 27 minutes faster, but a bit harder to follow.\nYou can also run nbdev_help from the terminal to see the full list of available commands:\n\n!nbdev_help\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config             Create a config file.\nnbdev_deploy                    Deploy docs to GitHub Pages\nnbdev_docs                      Create Quarto docs and README.md\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all directives and callouts in `fname` from v1 to v2\nnbdev_new                       Create an nbdev project.\nnbdev_prepare                   Export, test, and clean notebooks, and render README if needed\nnbdev_preview                   Preview docs locally\nnbdev_proc_nbs                  Process notebooks in `path` for docs rendering\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_readme                    None\nnbdev_release_both              Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them"
  },
  {
    "objectID": "getting_started.html#faq",
    "href": "getting_started.html#faq",
    "title": "Getting started",
    "section": "FAQ",
    "text": "FAQ\n\nQ: What is the warning “Found a cell containing mix of imports and computations. Please use separate cells”?\nA: You should not have cells that are not exported, and contain a mix of import statements along with other code. For instance, don’t do this in a single cell:\nimport some_module\nsome_module.something()\nInstead, split this into two cells, one which does import some_module, and the other which does some_module.something().\nThe reason for this is that when we create your documentation website, we ensure that all of the signatures for functions you document are up to date, by running the imports, exported cells, and show_doc functions in your notebooks. When you mix imports with other code, that other code will be run too, which can cause errors (or at least slowdowns) when creating your website.\n\n\nQ: Why is nbdev asking for root access? How do I install Quarto without root access?\nA: When you setup your first project, nbdev will attempt to automatically download and install Quarto for you. This is the program that we use to create your documentation website.\nQuarto’s standard installation process requires root access, and nbdev will therefore ask for your root password during installation. For most people, this will work fine and everything will be handled automatically – if so, you can skip over the rest of this section, which talks about installing without root access.\nIf you need to install Quarto without root access on Linux, first cd to wherever you want to store it, then download Quarto, and type:\ndpkg -x quarto*.deb .\nmv opt/quarto ./\nrmdir opt\nmkdir -p ~/.local/bin\nln -s \"$(pwd)\"/quarto/bin/quarto ~/.local/bin\nTo use this non-root version of Quarto, you’ll need ~/.local/bin in your PATH environment variable. (Alternatively, change the ln -s step to place the symlink somewhere else in your path.)\n\n\nQ: Someone told me not to use notebooks for “serious” software development!\nA: Watch this video. Don’t worry, we still get this too, despite having used nbdev for a wide range of “very serious” software projects over the last three years, including deep learning libraries, API clients, Python language extensions, terminal user interfaces, and more!"
  },
  {
    "objectID": "getting_started.html#contributing",
    "href": "getting_started.html#contributing",
    "title": "Getting started",
    "section": "Contributing",
    "text": "Contributing\nIf you want to contribute to nbdev, be sure to review the contributions guidelines. This project adheres to fastai’s code of conduct. By participating, you are expected to uphold this code. In general, we strive to abide by generally accepted best practices in open-source software development.\nMake sure you have nbdev’s git hooks installed by running nbdev_install_hooks in the cloned repository."
  },
  {
    "objectID": "getting_started.html#copyright",
    "href": "getting_started.html#copyright",
    "title": "Getting started",
    "section": "Copyright",
    "text": "Copyright\nCopyright © 2019 onward fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this project’s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository."
  },
  {
    "objectID": "explanations/config.html",
    "href": "explanations/config.html",
    "title": "Settings.ini",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\n\n[DEFAULT]\nlib_name = nbdev\ndescription = Create delightful software with Jupyter Notebooks\ncopyright = 2020 onwards, Jeremy Howard\nkeywords = nbdev fastai jupyter notebook export\nuser = fastai\nauthor = Jeremy Howard and Hamel Husain\nauthor_email = j@fast.ai\nbranch = master\nmin_python = 3.7\n\n\nYou can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved):\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\nbranch\nstr\nmaster\nRepo default branch\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nstr\n.\nPath to notebooks\n\n\nlib_path\nstr\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nstr\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nFalse\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool\nTrue\nRun Jupyter hooks?\n\n\nclean_ids\nbool\nTrue\nRemove ids from plaintext reprs?\n\n\ncustom_quarto_yml\nbool\nFalse\nUse a custom _quarto.yml?\n\n\n\n\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file."
  },
  {
    "objectID": "explanations/index.html",
    "href": "explanations/index.html",
    "title": "Explanations",
    "section": "",
    "text": "These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nSettings.ini\n\n\nThe nbdev configuration file\n\n\n\n\nDirectives\n\n\nA cheat sheet of directives available in nbdev.\n\n\n\n\nDocs Website\n\n\nHow nbdev renders a documentation website for your project.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "explanations/docs.html",
    "href": "explanations/docs.html",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default."
  },
  {
    "objectID": "explanations/docs.html#overview",
    "href": "explanations/docs.html#overview",
    "title": "Docs Website",
    "section": "Overview",
    "text": "Overview\nBelow is a diagram on how these concepts fit together.\n\n\n\n\nflowchart TB\n  %%styles\n  style JN fill:#FFA500\n  style FP fill:#cfe5ed\n  style SF fill:#dff1dd,stroke-dasharray: 5 5;\n  style QMD fill:#7286bb,color:#fff;\n  classDef files fill:#ede8ce ;\n  classDef code fill:#5695c7,color:#fff;\n  classDef container fill:#f9f9f6;\n  \n   %% list of nodes\n  FP(<strong>Processing Pipeline</strong>\\ntransforms notebook based\\non directives and front-matter)\n  E(execnb)\n  SD(\"show_doc\")\n  SS(<strong>Static Site</strong>\\nHTML, CSS and Javascript)\n  CF(\"Intermediate Output is stored in the <code>_procs/</code> directory\\n\\n<i>(This is a full copy of your Quarto project)</i>\")\n  class SD,E code;\n  \n  subgraph SF[\"<strong>Source Files</strong>\"]\n      JN([Jupyter\\nNotebook])\n      QMD([\"Quarto\\nMarkdown\\n(.qmd)\"])\n  end\n  \n  \n  %% connections to things inside Notebook Processor (NBP)\n  JN -- json --> FP\n  E -. \"cell execution\" .- SD\n  \n  subgraph NBP [\"&nbsp;<strong>Notebook Processor\\n</strong>&nbsp;\"]\n      SD -.- |\"render API docs\"|FP\n  end\n  \n  FP -- modified json with only\\nQuarto directives remaining --> CF\n  \n  subgraph Quarto [\"&nbsp;<strong>Quarto</strong>\\n&nbsp;<br>\"]\n      direction LR\n      F[[_quarto.yml]] .-> G[[custom.yml]] & H[[sidebar.yml]]\n      class F,G,H files;\n  end\n  \n  QMD --\"rendered\\ndirecty by Quarto\\n(no pre-processing required)\"--> CF\n  CF --> Quarto\n  Quarto --> SS\n  \n  class NBP,CF,Quarto container;"
  },
  {
    "objectID": "explanations/docs.html#customizing-quarto",
    "href": "explanations/docs.html#customizing-quarto",
    "title": "Docs Website",
    "section": "Customizing Quarto",
    "text": "Customizing Quarto\nYou can create a custom.yml file in the same location as your _quarto.yml file to override any values in _quarto.yml. For example, assume your _quarto.yml file looks contains this:\n\nwebsite:\n  title: \"nbdev\"\n  site-url: \"https://nbdev.fast.ai/\"\n  description: \"Create delightful software with Jupyter Notebooks\"\n  twitter-card: true\n  open-graph: true\n  repo-branch: master\n  repo-url: \"https://github.com/fastai/nbdev\"\n  repo-actions: [issue]\n  navbar:\n    background: primary\n    search: true\n    right:\n      - icon: github\n        href: \"https://github.com/fastai/nbdev\"\n  sidebar:\n    style: \"floating\"\n\nLet’s assume you want to customize your sidebar navigation options such that instead of “floating” for sidebar.style, you wanted your navbar to be “docked”. Additionally, lets assume you want a different background color using the sidebar.background field which is not in the configuration above.\nTo accomplish these tasks, you would create a custom.yml in the same location as _quarto.yml with these contents:\n\nwebsite:\n  sidebar:\n      style: \"docked\"\n      background: \"dark\"\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also set custom_quarto_yml = True in settings.ini if you wish to edit _quarto.yml directly instead of overriding settings in custom.yml.\n\n\n\nCustomizing The Sidebar\nBy default nbdev automatically generates sidebar.yml, which specifies the tree structure of your sidebar. nbdev infers the tree structure by inspecting the directory structure containing your source files. You can see an example of this by inspecting the folder structure of the notebooks directory in nbdev and the corresponding left-hand sidebar on this website. Leading numbers in filenames and directories are ignored when naming elements of the sidebar (which you can see examples of in this project’s notebooks directory).\nTo customize the sidebar, you must set custom_sidebar = true in settings.ini. This will prevent nbdev from regenerating this file every time the docs are re-built. This way, you an edit this file directly instead of overriding the sidebar with custom.yml."
  },
  {
    "objectID": "explanations/docs.html#how-show_doc-works",
    "href": "explanations/docs.html#how-show_doc-works",
    "title": "Docs Website",
    "section": "How show_doc works",
    "text": "How show_doc works\nWhen your documention website is built, all functions and classes you export to source code will be automatically documented with show_doc. This function outputs a summary of the symbol, showing its signature, docstring, and parameters. For instance, if you have this function:\n\ndef say_gday(\n    greeting:str=\"G'day\",  # Greeting to use\n    strine:bool=True,      # Use incomprehensible Aussie accent?\n    dropbears:bool=False): # Also warn about drop-bears?\n    \"Says g'day, the classic Aussie greeting\"\n    ...\n\nThis is how it’s rendered in the documentation, by automatically generating a temporary cell containing:\n\nshow_doc(say_gday)\n\n\nsay_gday\n\n say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False)\n\nSays g’day, the classic Aussie greeting\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngreeting\nstr\nG’day\nGreeting to use\n\n\nstrine\nbool\nTrue\nUse incomprehensible Aussie accent?\n\n\ndropbears\nbool\nFalse\nAlso warn about drop-bears?\n\n\n\n\n\nBecause this is done automatically any time you build your docs (including automatically by continuous integration), your documentation will always contain current information about your code.\nYou can also document code that’s not created in a notebook, by using show_doc with imported code. For instance, if we wanted to document release_conda, we can import it and call show_doc(release_conda):\n\nfrom nbdev.release import release_conda\nshow_doc(release_conda)\n\nsource\n\nrelease_conda\n\n release_conda (path:str='conda', do_build:<function bool_arg>=True,\n                build_args:str='', skip_upload:<function\n                store_true>=False, mambabuild:<function store_true>=False,\n                upload_user:str=None)\n\nCreate a meta.yaml file ready to be built into a package, and optionally build and upload it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\n\n\n\n\nAutomatic Cell Execution\nWhen your documentation is built, all your manually added show_doc cells are run automatically. nbdev also executes all cells containing an import statement, and all exported cells – that way we can be sure that the symbol used in your show_doc cell is available.\nWe don’t, however, execute any other cells. That’s because you wouldn’t want to wait for your entire notebook to run just to build your docs; for instance, your docs might demonstrate training a model which takes hours to complete!\nThis leads to an important rule when authoring nbdev notebooks:\n\n\n\n\n\n\nWarning\n\n\n\nDo not mix import statements (or calls to show_doc) with other code in a single cell. If you do, all the code in that cell will be executed every time you build your docs, which might lead to errors (since not all previous cells will have been executed.\nInstead, put your imports in separate cells, and calls to show_doc should contain only that one line of code – the show_doc call.\n\n\nNote that nbdev automatically hides the actual show_doc(...) line of code. So your users only see the output.\n\nForcing Cells To Execute\nSometimes you may want to execute additional cells beyond what is automatically executed by nbdev. For instance, on our Getting Started page we show a list of all nbdev commands, automatically generated with nbdev_help. We want this page to always have the most up to date list of commands and docs, so we want it to always execute when the docs are rendered. To do that, add the following directive to the top of a cell:\n#| exec_doc\nAlternatively, you can get nbdev to automatically execute all cells when rendering your docs, by adding the following to your notebook frontmatter:\n---\nexec_all: true\n---\n\n\nSkipping Execution\nLikewise, you can instruct nbdev to not execute any cells when rendering your docs with the following front matter:\n---\nskip_showdoc: true\n---\nOr ignore execution for a specific cell with this directive:\n#|eval: false\n\n\n\nWhy use show_doc?\nMany Python developers use sphinx autodoc to automatically document a whole module all at once. Whilst this can work reasonably well, we think there are huge benefits for both developers and users in using nbdev’s approach instead\nThe premise of nbdev’s approach is that your documentation is important enough to be worth you taking the time to think carefully though each thing you want to show your users, what examples you’re going to provide, maybe adding some images to explain more complex ideas, and so forth. Jupyter provides a terrific environment for creating just these kinds of documents. For instance, with Jupyter you can:\n\nPaste images directly from your clipboard into a cell\nInsert code and have it executed and the results displayed to users\nCreate a hierarchy of headings to help structure your page\n…and much more.\n\nWith show_doc, you can insert automatically-updated API details for your library anywhere in a page. That means that you get to decide exactly how your page should look, and what information is provided where. You don’t have to limit yourself to the limits of ASCII art for diagrams, and can include full end-to-end code walk-through of the processes your users will be following."
  },
  {
    "objectID": "explanations/docs.html#previewing-your-site-locally",
    "href": "explanations/docs.html#previewing-your-site-locally",
    "title": "Docs Website",
    "section": "Previewing Your Site Locally",
    "text": "Previewing Your Site Locally\nYou can preview your docs anytime by running nbdev_preview. While in preview mode, you can make updates to notebooks and it will be reflected (after a small delay) in your browser."
  },
  {
    "objectID": "explanations/docs.html#deploying-docs-with-github-actions",
    "href": "explanations/docs.html#deploying-docs-with-github-actions",
    "title": "Docs Website",
    "section": "Deploying Docs With GitHub Actions",
    "text": "Deploying Docs With GitHub Actions\nIf your nbdev project lives in GitHub, we include automation that deploys your documentation site for you on GitHub Pages.\nnbdev comes bundled with a workflow file that enables this automation. This workflow is automatically triggered whenever you change any of the content in your repo. The following GitHub Actions workflows will run to generate a docs site (in this order):\n\nDeploy to GitHub Pages: This workflow builds the docs with nbdev. This is defined in deploy.yaml and references fastai/workflows/quarto-ghp.\npages build and deployment: This is an internal built-in workflow that GitHub provides whenever GitHub pages are enabled.\n\nShould anything go wrong in your page build, you can always look at the logs of these workflows. Like other workflows, these can be found in the Actions tab of your repo:\n\n\n\n\n\nTo read more about GitHub Actions, see their docs."
  },
  {
    "objectID": "explanations/docs.html#deploying-your-docs-on-other-platforms",
    "href": "explanations/docs.html#deploying-your-docs-on-other-platforms",
    "title": "Docs Website",
    "section": "Deploying Your Docs On Other Platforms",
    "text": "Deploying Your Docs On Other Platforms\nYou can generate all of the static assets for your site (html, css, etc) by running the command nbdev_docs. After running this command, all of the files for your documentation site will be located in the _docs/ directory (the location is configurable by doc_path in settings.ini) at the root of your repository. This directory is not checked into git and is ignored by .gitignore, but you can use these files to deploy to any hosting platform you want.\nYou can also use the quarto publish command to render your docs on a wide variety of other platforms, which is discussed in the Quarto docs here. After running the command nbdev_docs, the quarto publish command must be run from the root of the _proc/ directory, which is located at the root of your repo. The built-in help of quarto publish provides a good overview of the various targets available:\n\n\n\n\n\n\nCall nbdev_docs and publish from the _proc/ directory\n\n\n\nTo use quarto publish with nbdev, you must run the nbdev_docs command to pre-process your notebooks before publishing your docs. As a reminder, nbdev_doc creates the directory _proc/ at the root of your project that Quarto uses to render your site.\nFor example, to publish a site to Netlify you can run the following command from the root of your repo:\nnbdev_docs && cd _proc && quarto publish netlify\n\n\n\n!quarto publish -h\n\n\n  Usage:   quarto publish [provider] [path]\n  Version: 1.1.75                          \n                                           \n\n  Description:\n\n    Publish a document or project. Available providers include:\n                                                               \n     - Quarto Pub (quarto-pub)                                 \n     - GitHub Pages (gh-pages)                                 \n     - RStudio Connect (connect)                               \n                                                               \n     - Netlify (netlify)                                       \n    Accounts are configured interactively during publishing.   \n    Manage/remove accounts with: quarto publish accounts       \n\n  Options:\n\n    -h, --help              - Show this help.                                     \n    --id          <id>      - Identifier of content to publish                    \n    --server      <server>  - Server to publish to                                \n    --token       <token>   - Access token for publising provider                 \n    --no-render             - Do not render before publishing.                    \n    --no-prompt             - Do not prompt to confirm publishing destination     \n    --no-browser            - Do not open a browser to the site after publishing  \n    --log         <level>   - Path to log file                                    \n    --log-level   <level>   - Log level (info, warning, error, critical)          \n    --log-format  <format>  - Log format (plain, json-stream)                     \n    --quiet                 - Suppress console output.                            \n\n  Commands:\n\n    help  [command]  - Show this help or the help of a sub-command.\n\n  Examples:\n\n    Publish project (prompt for provider):  quarto publish                                                  \n    Publish document (prompt for provider): quarto publish document.qmd                                     \n    Publish project to Netlify:             quarto publish netlify                                          \n    Publish with explicit target:           quarto publish netlify --id DA36416-F950-4647-815C-01A24233E294 \n    Publish project to GitHub Pages:        quarto publish gh-pages                                         \n    Publish project to RStudio Connect:     quarto publish connect                                          \n    Publish with explicit credentials:      quarto publish connect --server example.com --token 01A24233E294\n    Publish without confirmation prompt:    quarto publish --no-prompt                                      \n    Publish without rendering:              quarto publish --no-render                                      \n    Publish without opening browser:        quarto publish --no-browser                                     \n    Manage/remove publishing accounts:      quarto publish accounts"
  },
  {
    "objectID": "explanations/directives.html",
    "href": "explanations/directives.html",
    "title": "Directives",
    "section": "",
    "text": "Directives are special comments that are preceded by #| that control:\nnbdev augments Quarto by providing additional directives than what are available in Quarto. All Quarto directives can be used in nbdev notebooks.\nThis cheat sheet lists all nbdev directives in addition to some Quarto directives we believe are important. We recommend consulting the quarto docs to see all of the directives available to you.\nTo clarify the origin of directives we use the following emojis:"
  },
  {
    "objectID": "explanations/directives.html#cell-visibility",
    "href": "explanations/directives.html#cell-visibility",
    "title": "Directives",
    "section": "Cell Visibility",
    "text": "Cell Visibility\nThe following directives control cell visibility in rendered documentation:\n\n📓 #|hide\nHide cell input and output.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following will result in the contents of the cell and it’s output from being hidden:\n#|hide\nprint('you will not see this')\nNote that using #|hide is equivalent to using the Quarto directive #|include: false:\n#|include: false\nprint('you will not see this')\nSee the quarto docs for more information about #|include.\n\n\n\n\n\n🔵 #|echo: <true|false>\nToggle the visibility of code-cell inputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|echo: false\nprint('you can see the output but not the code!')\nwhich results in:\nyou can see the output but not the code!\n\n\n\n\n\n🔵 #|output: <true|false|asis>\nSetting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following cell will not display any output:\n#|output: false\n1 + 1\nThe following cell with #|output: asis will produce the output hello fastai rendered as markdown instead of a string:\n#|output: asis\nprint(\"`hello fastai`\")\n\n\n\n\n\n📓 #|hide_line\nHide a specific line of code in an input cell.\n\n\n\n\n\n\nExample\n\n\n\n\n\ndef _secret(): ...\n\nfor i in range(3):\n    _secret() #|hide_line\n    print(i)\nbecomes this:\n\ndef _secret(): ...\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n\n\n\n📓 #|filter_stream <keyword> ...\nFilter lines containing specific keywords in cell outputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|filter_stream FutureWarning MultiIndex\nprint('\\n'.join(['A line', 'Foobar baz FutureWarning blah', \n                 'zig zagMultiIndex zoom', 'Another line.']))\nwill output this:\n\n\nA line\nAnother line.\n\n\n\n\n\n\n\n🔵 #|code-fold: <show|true>\nThe #|code-fold directive allows you to collapse code cells. When set to true, the element is collapsed by default, when set to show show the element is shown by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWhen you set #|code-fold: true, the input cell is collapsed:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space\n\n\nWhen you set #|code-fold: show the input cell is shown but still in a collapsible element:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space"
  },
  {
    "objectID": "explanations/directives.html#generating-source-code",
    "href": "explanations/directives.html#generating-source-code",
    "title": "Directives",
    "section": "Generating Source Code",
    "text": "Generating Source Code\nThe following directives control how source code is exported from code cells.\n\n📓 #|default_exp <name>\nNames the module where cells with the #|export directive will be exported to by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#| default_exp baz\n\n# In a new notebook cell:\n\n#| export\ndef my_function(): pass\nIf our package is named: bitsnbytes then we can do:\nfrom bitsnbytes.baz import my_function\nYou can define the package name by using lib_name in settings.ini.\n\n\n\n\n\n📓 #|export\nExports the items in the cell into the generated module and documentation.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|export\ndef say_hello(to:str # name of person to say hello to\n             ):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nThe above cell will get exported to the module specified by #|default_exp. These exports are automatically included in __all__ for the module. To learn how export without inclusion in __all__, see the #|exporti directive.\nFurthermore, the documentation for this function will automatically be rendered like this:\n\n\nsay_hello\n\n say_hello (to:str)\n\nSay hello to somebody\n\n\n\n\nType\nDetails\n\n\n\n\nto\nstr\nname of person to say hello to\n\n\n\nThe docs are generated from this export using show_doc. See these docs for a detailed discussion of show_doc.\n\n\n\n\n\n\n📓 #|export <some.thing>\nSimilar to #|export, but instead of exporting to the module named by #|default_exp export to the specified module.\n\n\n\n\n\n\nExample\n\n\n\n\n\nIf our package is named: bitsnbytes, and we have previously included: #|default_exp core in this notebook, and we have an existing notebook with #|default_exp bar, then:\nEarlier in the notebook:\n#|default_exp core\nA new notebook cell:\n#|export bar\ndef foo(): pass\nthen we can import this as:\nfrom bitsnbytes.bar import foo\n\n\n\n\n\n📓 #|exporti\nAn internal export. Not included in __all__ or the docs. Useful for a function that is called by other functions in this module but is not part of the public API.\nEquivalently, you can prefix your function or method with _ e.g. def _private(): pass.\n\n\n📓 #|exports\nA source export. Like #|export but in addition to showing docs via showdoc.show_doc, it also shows the source code.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|exports\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nthis will produce the following output:\n\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody"
  },
  {
    "objectID": "explanations/directives.html#cell-execution",
    "href": "explanations/directives.html#cell-execution",
    "title": "Directives",
    "section": "Cell Execution",
    "text": "Cell Execution\nThe following directives allow you to control how cells are executed during docs rendering and testing.\n\n📓 #|exec_doc\nEnsures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here.\n\n\n\n\n\n\nExample\n\n\n\n\n\n\ndatetime.datetime.now()\n\ndatetime.datetime(2022, 8, 18, 9, 1, 43, 907609)\n\n\nHowever with the annotation:\n#|exec_doc\ndatetime.datetime.now()\nwe can see that the time has been updated:\n\ndatetime.datetime.now()\n\ndatetime.datetime(2022, 9, 11, 13, 49, 42, 95657)\n\n\n\n\n\n\n\n🔵 #|eval: <true|false>\nWhen set to false, the cell is ignored during testing.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|eval: false\nraise Exception(\"I'm not raised because I'm not run\")\n\n\n\n\n\nCell execution when there is no directive\nWhen a cell has no directives, cells are run by nbdev according to the behavior described here."
  },
  {
    "objectID": "api/config.html",
    "href": "api/config.html",
    "title": "config",
    "section": "",
    "text": "nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev’s config:\n\nIn the terminal: nbdev_create_config creates a config file (if you’re starting a new project use nbdev_new instead)\nIn your library: get_config returns a fastcore.foundation.Config object.\n\nRead on for more about how these work.\n\nsource\n\n\n\n nbdev_create_config (repo:str=None, user:str=None, author:str=None,\n                      author_email:str=None, description:str=None,\n                      path:str='.', cfg_name:str='settings.ini',\n                      lib_name='%(repo)s', branch='master',\n                      git_url='https://github.com/%(user)s/%(repo)s',\n                      custom_sidebar:<function bool_arg>=False,\n                      nbs_path='.', lib_path:str=None, doc_path='_docs',\n                      tst_flags='notest', version='0.0.1',\n                      doc_host='https://%(user)s.github.io',\n                      doc_baseurl='/%(repo)s', keywords='nbdev jupyter\n                      notebook python', license='apache2',\n                      copyright:str=None, status='3', min_python='3.7',\n                      audience='Developers', language='English',\n                      recursive:<function bool_arg>=False,\n                      black_formatting:<function bool_arg>=False,\n                      readme_nb='index.ipynb', title='%(lib_name)s',\n                      allowed_metadata_keys='',\n                      allowed_cell_metadata_keys='', jupyter_hooks=True,\n                      clean_ids=True, custom_quarto_yml=False)\n\nCreate a config file.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\nbranch\nstr\nmaster\nRepo default branch\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nstr\n.\nPath to notebooks\n\n\nlib_path\nstr\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nstr\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nFalse\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool\nTrue\nRun Jupyter hooks?\n\n\nclean_ids\nbool\nTrue\nRemove ids from plaintext reprs?\n\n\ncustom_quarto_yml\nbool\nFalse\nUse a custom _quarto.yml?\n\n\n\nThe table above also serves as a full reference of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved). For more about PyPI classifiers, see Classifiers.\nYou can create a config file by passing all of the required settings via the command line, as well as any optional settings you’d like to override, for example:\nnbdev_create_config --repo nbdev --user fastai --author fastai \\\n                    --author_email info@fast.ai --description 'A test project'\nIf you don’t provide required settings from the command line, we’ll try to to infer them from git and GitHub. Finally, you’ll be asked to manually input any required settings that we couldn’t automatically fill in.\n\nsource\n\n\n\n\n get_config (cfg_name='settings.ini', path=None)\n\nReturn nbdev config.\nSearches up from path until cfg_name is found. User settings are loaded from ~/.config/nbdev/{cfg_name}. Unspecified optional settings return defaults.\nSee nbdev_create_config for a full reference of nbdev’s settings.\n\ncfg = get_config()\n\ncfg is a fastcore Config object, so you can access keys as attributes:\n\np = Path.cwd().parent.parent\ntest_eq(cfg.lib_name, 'nbdev')\ntest_eq(cfg.git_url, 'https://github.com/fastai/nbdev')\n\nIts own path and parent are attributes too:\n\ntest_eq(cfg.config_path, p)\ntest_eq(cfg.config_file, p/'settings.ini')\n\nPaths are relative to the project:\n\ntest_eq(cfg.doc_path, p/'_docs')\ntest_eq(cfg.lib_path, p/'nbdev')\ntest_eq(cfg.nbs_path, p/'nbs')\n\nIt automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren’t explicitly defined:\n\nwith tempfile.TemporaryDirectory() as d, working_directory(d):\n    Config('.', 'test_settings.ini', {'repo': 'my-project', 'author': 'fastai', 'nbs_path': 'nbs'});\n    cfg = get_config('test_settings.ini', '.')\n    test_eq(cfg.repo, 'my-project')\n    test_eq(cfg.lib_path.name, 'my_project')\n    test_eq(cfg.copyright, '2022 onwards, fastai')\n\nIn fact, you can return a default config even if you don’t have a settings file. This is to support certain nbdev commands work outside of nbdev repos:\n\ncfg = get_config('test_settings.ini', '.')\ntest_eq(cfg.lib_path, Path('nbdev').resolve())\ntest_eq(cfg.nbs_path, Path('.').resolve())\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file (by default, although we follow the broader XDG specification). For example, you could globally disable nbdev’s Jupyter hooks by creating a user settings file with jupyter_hooks = False.\n\nsource\n\n\n\n\n config_key (c, default=None, path=True, missing_ok=None)\n\nDeprecated: use get_config().get or get_config().path instead."
  },
  {
    "objectID": "api/config.html#helpers",
    "href": "api/config.html#helpers",
    "title": "config",
    "section": "Helpers",
    "text": "Helpers\n\nsource\n\ncreate_output\n\n create_output (txt, mime)\n\nAdd a cell output containing txt of the mime text MIME sub-type\n\nsource\n\n\nshow_src\n\n show_src (src, lang='python')\n\n\nshow_src(\"print(create_output('text', 'text/plain'))\")\n\nprint(create_output('text', 'text/plain'))"
  },
  {
    "objectID": "api/config.html#exporting-a-basic-module",
    "href": "api/config.html#exporting-a-basic-module",
    "title": "config",
    "section": "Exporting a basic module",
    "text": "Exporting a basic module\n\nsource\n\nadd_init\n\n add_init (path=None)\n\nAdd __init__.py in all subdirs of path containing python files if it’s not there already.\n\nsource\n\n\nupdate_version\n\n update_version (path=None)\n\nAdd or update __version__ in the main __init__.py of the library.\nPython modules require a __init.py__ file in all directories that are modules. We assume that all directories containing a python file (including in subdirectories of any depth) is a module, and therefore add a __init__.py to each.\n\nwith tempfile.TemporaryDirectory() as d:\n    d = Path(d)\n    (d/'a/b').mkdir(parents=True)\n    (d/'a/b/f.py').touch()\n    (d/'a/c').mkdir()\n    add_init(d)\n    assert not (d/'a/c'/_init).exists(), \"Should not add init to dir without py file\"\n    for e in [d, d/'a', d/'a/b']: assert (e/_init).exists(),f\"Missing init in {e}\"\n\n\nsource\n\n\nwrite_cells\n\n write_cells (cells, hdr, file, offset=0)\n\nWrite cells to file along with header hdr starting at index offset (mainly for nbdev internal use).\nThis is a simple exporter with just enough functionality to correctly export this notebook, in order to bootstrap the creation of nbdev itself."
  },
  {
    "objectID": "api/maker.html#variable-helpers",
    "href": "api/maker.html#variable-helpers",
    "title": "maker",
    "section": "Variable helpers",
    "text": "Variable helpers\nThese functions let us find and modify the definitions of variables in Python modules.\n\nsource\n\nfind_var\n\n find_var (lines, varname)\n\nFind the line numbers where varname is defined in lines\n\nt = '''a_=(1,\n  2,\n  3)\n\nb_=3'''\ntest_eq(find_var(t.splitlines(), 'a_'), (0,3))\ntest_eq(find_var(t.splitlines(), 'b_'), (4,5))\n\n\nsource\n\n\nread_var\n\n read_var (code, varname)\n\nEval and return the value of varname defined in code\n\ntest_eq(read_var(t, 'a_'), (1,2,3))\ntest_eq(read_var(t, 'b_'), 3)\n\n\nsource\n\n\nupdate_var\n\n update_var (varname, func, fn=None, code=None)\n\nUpdate the definition of varname in file fn, by calling func with the current definition\n\ng = exec_new(t)\ntest_eq((g['a_'],g['b_']), ((1,2,3),3))\nt2 = update_var('a_', lambda o:0, code=t)\nexec(t2, g)\ntest_eq((g['a_'],g['b_']), (0,3))\nt3 = update_var('b_', lambda o:0, code=t)\nexec(t3, g)\ntest_eq((g['a_'],g['b_']), ((1,2,3),0))\n\n\nsource\n\n\nModuleMaker\n\n ModuleMaker (dest, name, nb_path, is_new=True, parse=True)\n\nHelper class to create exported library from notebook source cells\nIn order to export a notebook, we need an way to create a Python file. ModuleMaker fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set is_new to True if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in fname. Finally, if the source in the notebooks should not be parsed by Python (such as partial class declarations in cells), parse should be set to False.\n\nNote: If doing so, then the __all__ generation will be turned off as well.\n\n\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=True)\nmm.fname\n\nPath('tmp/test/testing.py')\n\n\n\nsource\n\n\ndecor_id\n\n decor_id (d)\n\nid attr of decorator, regardless of whether called as function or bare\n\nsource\n\n\nModuleMaker.make_all\n\n ModuleMaker.make_all (cells)\n\nCreate __all__ with all exports in cells\n\nsource\n\n\nmake_code_cells\n\n make_code_cells (*ss)\n\nWe want to add an __all__ to the top of the exported module. This methods autogenerates it from all code in cells.\n\nnb = make_code_cells(\"from __future__ import print_function\", \"def a():...\", \"def b():...\",\n                      \"c=d=1\", \"_f=1\", \"_g=1\", \"_h=1\", \"_all_=['_g', _h]\", \"@patch\\ndef h(self:ca):...\")\ntest_eq(set(mm.make_all(nb)), set(['a','b','c','d', '_g', '_h']))\n\n\nsource\n\n\nrelative_import\n\n relative_import (name, fname, level=0)\n\nConvert a module name to a name relative to fname\n\ntest_eq(relative_import('nbdev.core', \"xyz\"), 'nbdev.core')\ntest_eq(relative_import('nbdev.core', 'nbdev'), '.core')\n_p = Path('fastai')\ntest_eq(relative_import('fastai.core', _p/'vision'), '..core')\ntest_eq(relative_import('fastai.core', _p/'vision/transform'), '...core')\ntest_eq(relative_import('fastai.vision.transform', _p/'vision'), '.transform')\ntest_eq(relative_import('fastai.notebook.core', _p/'data'), '..notebook.core')\ntest_eq(relative_import('fastai.vision', _p/'vision'), '.')\ntest_eq(relative_import('fastai', _p), '.')\ntest_eq(relative_import('fastai', _p/'vision'), '..')\ntest_eq(relative_import('fastai', _p/'vision/transform'), '...')\n\n\nsource\n\n\nNbCell.import2relative\n\n NbCell.import2relative (cell:execnb.nbio.NbCell, libname)\n\n\nsource\n\n\nupdate_import\n\n update_import (source, tree, libname, f=<function relative_import>)\n\n\nss = \"from nbdev.export import *\\nfrom nbdev.a.b import *\"\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbdev')\ntest_eq(cell.source, 'from .export import *\\nfrom .a.b import *')\n\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbdev/a')\ntest_eq(cell.source, 'from ..export import *\\nfrom .b import *')\n\n\nsource\n\n\nModuleMaker.make\n\n ModuleMaker.make (cells, all_cells=None, lib_path=None)\n\nWrite module containing cells with __all__ generated from all_cells\n\ncells = make_code_cells(\"from __future__ import print_function\",\n                        \"_doc_ = 'module docstring here'\",\n                        \"#|export\\ndef a(): ...\", \"def b(): ...\")\nmm.make(cells, L([cells[2]]))\nshow_src(Path('tmp/test/testing.py').read_text())\n\n\"\"\"module docstring here\"\"\"\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb.\n\n# %% ../../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['a']\n\n# %% ../../01_export.ipynb 1\n_doc_ = 'module docstring here'\n\n# %% ../../01_export.ipynb 2\n#|export\ndef a(): ...\n\n# %% ../../01_export.ipynb 3\ndef b(): ...\n\n\nPass all_cells=[] or parse=False if you don’t want any __all__ added.\nPassing parse=False is also handy for when writing broken up functions or classes that ast.parse might not like but still want it to be exported, such as having a cell with:\n#|export\nclass A:\nNote that by doing so we cannot properly generate a __all__, so we assume that it is unwanted.\n\nam = ModuleMaker(dest='tmp', name='test.testing_noall', nb_path=Path.cwd()/'01_export.ipynb', is_new=True, parse=False)\nam.fname\n\nPath('tmp/test/testing_noall.py')\n\n\n\ncells = make_code_cells(\"from __future__ import print_function\", \"#|export\\ndef a(): ...\", \"#|export\\nclass A:\")\nam.make(cells)\nshow_src(Path('tmp/test/testing_noall.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb.\n\n# %% ../../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% ../../01_export.ipynb 1\n#|export\ndef a(): ...\n\n# %% ../../01_export.ipynb 2\n#|export\nclass A:\n\n\nIf is_new=False then the additional definitions are added to the bottom, and any existing __all__ is updated with the newly-added symbols.\n\nc2 = make_code_cells(\"def c(): ...\", \"def d(): ...\")\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=False)\nmm.make(c2, c2)\n\n\nshow_src(Path('tmp/test/testing.py').read_text())\n\n\"\"\"module docstring here\"\"\"\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb.\n\n# %% ../../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['a', 'c', 'd']\n\n# %% ../../01_export.ipynb 1\n_doc_ = 'module docstring here'\n\n# %% ../../01_export.ipynb 2\n#|export\ndef a(): ...\n\n# %% ../../01_export.ipynb 3\ndef b(): ...\n\n# %% ../../01_export.ipynb 0\ndef c(): ...\n\n# %% ../../01_export.ipynb 1\ndef d(): ...\n\n\n\ntry:\n    g = exec_import('tmp.test.testing', '*')\n    for s in \"a c d\".split(): assert s in g, s\n    assert 'b' not in g\n    assert g['a']() is None\nfinally: shutil.rmtree('tmp')"
  },
  {
    "objectID": "api/migrate.html",
    "href": "api/migrate.html",
    "title": "migrate",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "api/migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "href": "api/migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "title": "migrate",
    "section": "Convert nbdev v1 projects to nbdev v2",
    "text": "Convert nbdev v1 projects to nbdev v2\n\nDirectives\nnbdev v2 directives start with a #| whereas v1 directives were comments without a pipe |.\n\nsource\n\n\n_repl_directives\n\n _repl_directives (code_str)\n\nfor example, if any of the lines below are valid nbdev v1 directives, they replaced with a #|:\n\n_test_dir = \"\"\"\n#default_exp\n #export\n# collapse-show\n#collapse-hide\n#collapse\n# collapse_output\nnot_dir='#export'\n# hide_input\nfoo\n\"\"\"\ntest_eq(_repl_directives(_test_dir),\n\"\"\"\n#| default_exp\n#| export\n#| code-fold: show\n#| code-fold: true\n#| code-fold: true\n# collapse_output\nnot_dir='#export'\n#| hide_input\nfoo\n\"\"\")"
  },
  {
    "objectID": "api/migrate.html#callouts",
    "href": "api/migrate.html#callouts",
    "title": "migrate",
    "section": "Callouts",
    "text": "Callouts\nIn fastpages, there was a markdown shortuct for callouts for Note, Tip, Important and Warning with block quotes (these only worked in notebooks). Since Quarto has its own callout blocks with markdown syntax, we do not implement these shortcuts in nbdev. Instead, we offer a manual conversion utility for these callouts so that you can migrate from fastpages to Quarto.\n\nsource\n\n_convert_callout\n\n _convert_callout (s)\n\nConvert nbdev v1 to v2 callouts.\nFor example, the below markdown:\n\n_callouts=\"\"\"\n## Boxes / Callouts\n\n> Warning: There will be no second warning!\n\nOther text\n\n> Important: Pay attention! It's important.\n\n> Tip: This is my tip.\n\n> Note: Take note of `this.`\n\"\"\"\n\nGets converted to:\n\n\n\n## Boxes / Callouts\n\n:::{.callout-warning}\n\nThere will be no second warning!\n\n:::\n\nOther text\n\n:::{.callout-important}\n\nPay attention! It's important.\n\n:::\n\n\n\nsource\n\n\nmigrate_nb\n\n migrate_nb (path, overwrite=True)\n\nMigrate Notebooks from nbdev v1 and fastpages.\n\nsource\n\n\nmigrate_md\n\n migrate_md (path, overwrite=True)\n\nMigrate Markdown Files from fastpages.\n\nsource\n\n\nnbdev_migrate\n\n nbdev_migrate (path:str=None, no_skip:bool=False)\n\nConvert all markdown and notebook files in path from v1 to v2\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nA path or glob containing notebooks and markdown files to migrate\n\n\nno_skip\nbool\nFalse\nDo not skip directories beginning with an underscore"
  },
  {
    "objectID": "api/processors.html",
    "href": "api/processors.html",
    "title": "processors",
    "section": "",
    "text": "On this page we’ll be using this private helper to process a notebook and return the results, to simplify testing:\n\ndef _run_procs(procs=None, return_nb=False, path=_test_file):\n    nbp = NBProcessor(path, procs)\n    nbp.process()\n    if return_nb: return nbp.nb\n    return '\\n'.join([str(cell) for cell in nbp.nb.cells])\n\n\nsource\n\npopulate_language\n\n populate_language (nb)\n\nSet cell language based on NB metadata and magics\n\nsource\n\n\ninsert_warning\n\n insert_warning (nb)\n\nInsert Autogenerated Warning Into Notebook after the first cell.\nThis preprocessor inserts a warning in the markdown destination that the file is autogenerated. This warning is inserted in the second cell so we do not interfere with front matter.\n\nres = _run_procs(insert_warning)\nassert \"<!-- WARNING: THIS FILE WAS AUTOGENERATED!\" in res\n\n\nL('foo', None, 'a').filter(lambda x:x == 1)\n_tstre = re.compile('a')\n\n\nsource\n\n\nadd_show_docs\n\n add_show_docs (nb)\n\nAdd show_doc cells after exported cells, unless they are already documented\n\nsource\n\n\ncell_lang\n\n cell_lang (cell)\n\n\nres = _run_procs([populate_language, add_show_docs])\nassert \"show_doc(some_func)'\" in res\nassert \"show_doc(and_another)'\" in res\nassert \"show_doc(another_func)'\" not in res\n\n\nsource\n\n\nadd_links\n\n add_links (cell)\n\nAdd links to markdown cells\n\nres = _run_procs(add_links)\nassert \"[`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array)\" in res\nassert \"[`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker) but not a link to `foobar`.\" in res\nassert \"A link in a docstring: [`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker).\" in res\nassert \"And not a link to <code>dict2nb</code>.\" in res\n\nGets rid of colors that are streamed from standard out, which can interfere with static site generators:\n\nsource\n\n\nstrip_ansi\n\n strip_ansi (cell)\n\nStrip Ansi Characters.\n\nres = _run_procs(strip_ansi)\nassert not _re_ansi_escape.findall(res)\n\n\nsource\n\n\nstrip_hidden_metadata\n\n strip_hidden_metadata (cell)\n\nStrips “hidden” metadata property from code cells so it doesn’t interfere with docs rendering\n\nsource\n\n\nhide_\n\n hide_ (cell)\n\nHide cell from output\n\nres = _run_procs(hide_)\nassert 'you will not be able to see this cell at all either' not in res\n\n\nsource\n\n\nhide_line\n\n hide_line (cell)\n\nHide lines of code in code cells with the directive hide_line at the end of a line of code\n\nres = _run_procs(hide_line)\nassert r\"def show():\\n    a = 2\\n    b = 3\" not in res\nassert r\"def show():\\n    a = 2\"                in res\n\n\nsource\n\n\nfilter_stream_\n\n filter_stream_ (cell, *words)\n\nRemove output lines containing any of words in cell stream output\n\nres = _run_procs(filter_stream_)\nexp=r\"'A line\\n', 'Another line.\\n'\"\nassert exp in res\n\n\nsource\n\n\nclean_magics\n\n clean_magics (cell)\n\nA preprocessor to remove cell magic commands\n\nres = _run_procs(clean_magics)\nassert \"%%\" not in res\n\n\nsource\n\n\nrm_header_dash\n\n rm_header_dash (cell)\n\nRemove headings that end with a dash -\n\nres = _run_procs(rm_header_dash)\nassert 'some words' in res\nassert 'A heading to Hide' not in res\nassert 'Yet another heading to hide' not in res\n\n\nsource\n\n\nrm_export\n\n rm_export (cell)\n\nRemove cells that are exported or hidden\n\nres = _run_procs(rm_export)\nassert 'dontshow' not in res\n\n\nsource\n\n\nclean_show_doc\n\n clean_show_doc (cell)\n\nRemove ShowDoc input cells\n\nsource\n\n\nexec_show_docs\n\n exec_show_docs (nb)\n\nExecute cells needed for show_docs output, including exported cells and imports\n\nres = _run_procs([add_show_docs, exec_show_docs])\nassert res\n\n\nsource\n\n\nFilterDefaults\n\n FilterDefaults ()\n\nOverride FilterDefaults to change which notebook processors are used"
  },
  {
    "objectID": "api/serve.html",
    "href": "api/serve.html",
    "title": "serve",
    "section": "",
    "text": "source\n\nproc_nbs\n\n proc_nbs (path:str='', n_workers:int=2, force:bool=False,\n           file_glob:str='', symlinks:bool=False, file_re:str=None,\n           folder_re:str=None, skip_file_glob:str=None,\n           skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nProcess notebooks in path for docs rendering\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nPath to notebooks\n\n\nn_workers\nint\n2\nNumber of workers\n\n\nforce\nbool\nFalse\nIgnore cache and build all\n\n\nfile_glob\nstr\n\nOnly include files matching glob\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex"
  },
  {
    "objectID": "api/cli.html",
    "href": "api/cli.html",
    "title": "cli",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "api/cli.html#help",
    "href": "api/cli.html#help",
    "title": "cli",
    "section": "Help",
    "text": "Help\n\nsource\n\nchelp\n\n chelp ()\n\nShow help for all console scripts\n\nchelp()\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config             Create a config file.\nnbdev_deploy                    Deploy docs to GitHub Pages\nnbdev_docs                      Create Quarto docs and README.md\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all markdown and notebook files in `path` from v1 to v2\nnbdev_new                       Create an nbdev project.\nnbdev_prepare                   Export, test, and clean notebooks, and render README if needed\nnbdev_preview                   Preview docs locally\nnbdev_proc_nbs                  Process notebooks in `path` for docs rendering\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_readme                    None\nnbdev_release_both              Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them"
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API",
    "section": "",
    "text": "This section contains API details for each of nbdev’s python submodules. This reference documentation is mainly useful for people looking to customise or build on top of nbdev, or wanting detailed information about how nbdev works.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nconfig\n\n\nConfiguring nbdev and bootstrapping notebook export\n\n\n\n\nmaker\n\n\nCreate one or more modules from selected notebook cells\n\n\n\n\nprocess\n\n\nA notebook processor\n\n\n\n\nexport\n\n\nExporting a notebook to a library\n\n\n\n\ndoclinks\n\n\nGenerating a documentation index from a module\n\n\n\n\nsync\n\n\nPropagating small changes in the library back to notebooks\n\n\n\n\nmerge\n\n\nFix merge conflicts in jupyter notebooks\n\n\n\n\nshowdoc\n\n\nDisplay symbol documentation in notebook and website\n\n\n\n\nfrontmatter\n\n\nA YAML and formatted-markdown frontmatter processor\n\n\n\n\nprocessors\n\n\nSome processors for NBProcessor\n\n\n\n\nclean\n\n\nStrip superfluous metadata from notebooks\n\n\n\n\ntest\n\n\nRun unit tests on notebooks in parallel\n\n\n\n\ncli\n\n\nCLI commands\n\n\n\n\nquarto\n\n\nInstall and interact with Quarto from nbdev\n\n\n\n\nqmd\n\n\nBasic qmd generation helpers (experimental)\n\n\n\n\nmigrate\n\n\nUtilities for migrating to nbdev\n\n\n\n\nserve\n\n\nA parallel ipynb processor (experimental)\n\n\n\n\nrelease\n\n\nAuto-generated tagged releases and release notes from GitHub issues\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "api/qmd.html",
    "href": "api/qmd.html",
    "title": "qmd",
    "section": "",
    "text": "source\n\nmeta\n\n meta (md, classes=None, style=None, **kwargs)\n\nA metadata section for qmd div in {}\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmd\n\n\nMarkdown to add meta to\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\ndiv\n\n div (txt, classes=None, style=None, **kwargs)\n\nA qmd div with optional metadata section\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\n\n\nMarkdown to add meta to\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nimg\n\n img (fname, classes=None, style=None, height=None, relative=None,\n      link=False, **kwargs)\n\nA qmd image\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\n\n\nImage to link to\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nheight\nNoneType\nNone\nHeight attribute\n\n\nrelative\nNoneType\nNone\nTuple of (position,px)\n\n\nlink\nbool\nFalse\nHyperlink to this image\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nbtn\n\n btn (txt, link, classes=None, style=None, **kwargs)\n\nA qmd button\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\n\n\nButton text\n\n\nlink\n\n\nButton link URL\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\ntbl_row\n\n tbl_row (cols:list)\n\nCreate a markdown table row from cols\n\n\n\n\nType\nDetails\n\n\n\n\ncols\nlist\nAuto-stringified columns to show in the row\n\n\n\n\nsource\n\n\ntbl_sep\n\n tbl_sep (sizes:int|list=3)\n\nCreate a markdown table separator with relative column size sizes\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsizes\nint | list\n3\nList of column sizes, or single int if all sizes the same"
  },
  {
    "objectID": "api/frontmatter.html",
    "href": "api/frontmatter.html",
    "title": "frontmatter",
    "section": "",
    "text": "source\n\nFrontmatterProc\n\n FrontmatterProc (nb)\n\nA YAML and formatted-markdown frontmatter processor\nYAML frontmatter can be added to notebooks in one of two ways:\n\nBy adding a raw notebook cell with --- as the first and last lines, and YAML between them, or\nA specially formatted markdown cell. The first line should be start with a single # (creating an H1 heading), and becomes the title. Then, optionally, a line beginning with > (creating a quote block), which becomes the description. Finally, zero or more lines beginning with - (creating a list), each of which contains YAML. (If you already have “title” defined in frontmatter in a raw cell, then markdown cells will be ignored.)\n\nFor instance, our test notebook contains the following markdown cell:\n# a title\n> A description\n- key1: value1\n- key2: value2\n- categories: [c1, c2]\nIt also contains the following raw cell:\n---\nexecute:\n  echo: false\n---\nWhen we process with FrontmatterProc, these will both be removed, and a single raw cell will be added to the top, containing the combined YAML frontmatter:\n\nnbp = NBProcessor(_test_file, procs=FrontmatterProc)\nnbp.process()\nprint(nbp.nb.cells[0].source)\n\n---\ncategories:\n- c1\n- c2\ndescription: A description\nexecute:\n  echo: false\nkey1: value1\nkey2: value2\noutput-file: foobar.html\ntitle: a title\n\n---\n\n\n\n\nIn addition, a frontmatter_ attr will be added to the notebook, containing this information as a dict:\n\nd = nbp.nb.frontmatter_\nd\n\n{'execute': {'echo': False},\n 'title': 'a title',\n 'description': 'A description',\n 'key1': 'value1',\n 'key2': 'value2',\n 'categories': ['c1', 'c2'],\n 'output-file': 'foobar.html'}"
  },
  {
    "objectID": "api/export.html",
    "href": "api/export.html",
    "title": "export",
    "section": "",
    "text": "source\n\nExportModuleProc\n\n ExportModuleProc ()\n\nA processor which exports code to a module\nSpecify dest where the module(s) will be exported to, and optionally a class to use to create the module (ModuleMaker, by default).\nExported cells are stored in a dict called modules, where the keys are the modules exported to. Those without an explicit module are stored in the '#' key, which will be exported to default_exp.\n\neverything_fn = '../../tests/01_everything.ipynb'\n\nexp = ExportModuleProc()\nproc = NBProcessor(everything_fn, exp)\nproc.process()\ntest_eq(exp.default_exp, 'everything')\nassert 'print_function'  in exp.modules['#'][0].source\nassert 'h_n' in exp.in_all['some.thing'][0].source\n\n\nsource\n\n\nblack_format\n\n black_format (cell, force=False)\n\nProcessor to format code with black\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell\n\n\nCell to format\n\n\nforce\nbool\nFalse\nTurn black formatting on regardless of settings.ini\n\n\n\n\n_cell = read_nb('../../tests/black.ipynb')['cells'][0]\nblack_format(_cell, force=True)\ntest_eq(_cell.source, 'j = [1, 2, 3]')\n\n\nsource\n\n\nnb_export\n\n nb_export (nbname, lib_path=None, procs=<function black_format>,\n            debug=False, mod_maker=<class 'nbdev.maker.ModuleMaker'>)\n\nCreate module(s) from notebook\nLet’s check we can import a test file:\n\nshutil.rmtree('tmp', ignore_errors=True)\nnb_export('../../tests/00_some.thing.ipynb', 'tmp')\n\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a'])\ntest_eq(g['tmp'].some.thing.a, 1)\n\nWe’ll also check that our ‘everything’ file exports correctly:\n\nnb_export(everything_fn, 'tmp')\n\ng = exec_new('import tmp.everything; from tmp.everything import *')\n_alls = L(\"a b d e m n o p q\".split())\nfor s in _alls.map(\"{}_y\"): assert s in g, s\nfor s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\".split(): assert s not in g, s\nfor s in _alls.map(\"{}_y\") + [\"c_y_nall\", \"_f_y_nall\"]: assert hasattr(g['tmp'].everything,s), s\n\nThat notebook should also export one extra function to tmp.some.thing:\n\ndel(sys.modules['tmp.some.thing']) # remove from module cache\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a','h_n'])\ntest_eq(g['tmp'].some.thing.h_n(), None)\n\n\nPath('../nbdev/export.py').unlink(missing_ok=True)\nnb_export('04a_export.ipynb')\n\ng = exec_new('import nbdev.export')\nassert hasattr(g['nbdev'].export, 'nb_export')"
  },
  {
    "objectID": "api/process.html",
    "href": "api/process.html",
    "title": "process",
    "section": "",
    "text": "Special comments at the start of a cell can be used to provide information to nbdev about how to process a cell, so we need to be able to find the location of these comments.\n\nminimal = read_nb('../../tests/minimal.ipynb')\n\n\nsource\n\nnb_lang\n\n nb_lang (nb)\n\n\nsource\n\n\nfirst_code_ln\n\n first_code_ln (code_list, re_pattern=None, lang='python')\n\nget first line number where code occurs, where code_list is a list of code\n\n_tst = \"\"\" \n#|default_exp\n #|export\n#|hide_input\nfoo\n\"\"\"\ntest_eq(first_code_ln(_tst.splitlines(True)), 4)\n\n\nsource\n\n\nextract_directives\n\n extract_directives (cell, remove=True, lang='python')\n\nTake leading comment directives from lines of code in ss, remove #|, and split\nComment directives start with #|, followed by whitespace delimited tokens, which extract_directives extracts from the start of a cell, up until a blank line or a line containing something other than comments. The extracted lines are removed from the source.\n\nexp  = AttrDict(source = \"\"\"#|export module\n#|eval:false\n#| hide\n# | foo bar\n# |woo: baz\n1+2\n#bar\"\"\")\ntest_eq(extract_directives(exp), {'export':['module'], 'hide':[], 'eval:': ['false'], 'foo': ['bar'], 'woo:': ['baz']})\ntest_eq(exp.source, '#|eval: false\\n# |woo: baz\\n1+2\\n#bar')\n\n\nsource\n\n\nopt_set\n\n opt_set (var, newval)\n\nnewval if newval else var\n\nsource\n\n\ninstantiate\n\n instantiate (x, **kwargs)\n\nInstantiate x if it’s a type\n\nsource\n\n\nNBProcessor\n\n NBProcessor (path=None, procs=None, nb=None, debug=False,\n              rm_directives=True, process=False)\n\nProcess cells and nbdev comments in a notebook\nCell processors can be callables (e.g regular functions), in which case they are called for every cell (set a cell’s source to None to remove the cell):\n\neverything_fn = '../../tests/01_everything.ipynb'\n\ndef print_execs(cell):\n    if 'exec' in cell.source: print(cell.source)\n\nNBProcessor(everything_fn, print_execs).process()\n\n---\ntitle: Foo\nexecute:\n  echo: false\n---\nexec(\"o_y=1\")\nexec(\"p_y=1\")\n_all_ = [o_y, 'p_y']\n\n\nComment directives are put in a cell attribute directive_ as a dictionary keyed by directive name:\n\ndef printme_func(cell):\n    if cell.directives_ and 'printme' in cell.directives_: print(cell.directives_['printme'])\n\nNBProcessor(everything_fn, printme_func).process()\n\n['testing']\n\n\nHowever, a more convenient way to handle comment directives is to use a class as a processor, and include a method in your class with the same name as your directive, surrounded by underscores:\n\nclass _PrintExample:\n    def _printme_(self, cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, _PrintExample()).process()\n\ntesting\n\n\nIn the case that your processor supports just one comment directive, you can just use a regular function, with the same name as your directive, but with an underscore appended – here printme_ is identical to _PrintExample above:\n\ndef printme_(cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, printme_).process()\n\ntesting\n\n\n\nNBProcessor(everything_fn, _PrintExample()).process()\n\ntesting\n\n\n\nsource\n\n\nProcessor\n\n Processor (nb)\n\nBase class for processors\nFor more complex behavior, inherit from Processor, and override one of more of begin() (called before any cells are processed), cell() (called for each cell), and end() (called after all cells are processed). You can also include comment directives (such as the _printme example above) in these subclasses. Subclasses will automatically have access to self.nb, containing the processed notebook.\n\nclass CountCellProcessor(Processor):\n    def begin(self):\n        print(f\"First cell:\\n{self.nb.cells[0].source}\")\n        self.count=0\n    def cell(self, cell):\n        if cell.cell_type=='code': self.count += 1\n    def end(self): print(f\"* There were {self.count} code cells\")\n\n\nNBProcessor(everything_fn, CountCellProcessor).process()\n\nFirst cell:\n---\ntitle: Foo\nexecute:\n  echo: false\n---\n* There were 26 code cells"
  },
  {
    "objectID": "api/merge.html",
    "href": "api/merge.html",
    "title": "merge",
    "section": "",
    "text": "When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function nbdev_fix to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this:\n<<<<<< HEAD\n\n# local code here\n\n======\n\n# remote code here\n\n>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\nBelow is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can’t be opened in jupyter notebook.\n\nbroken = Path('../../tests/example.ipynb.broken')\ntst_nb = broken.read_text()\nprint(tst_nb)\n\n{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 6,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"3\"\n      ]\n     },\n     \"execution_count\": 6,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n<<<<<<< HEAD\n    \"z=3\\n\",\n=======\n    \"z=2\\n\",\n>>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"execution_count\": 5,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"6\"\n      ]\n     },\n<<<<<<< HEAD\n     \"execution_count\": 7,\n=======\n     \"execution_count\": 5,\n>>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"x=3\\n\",\n    \"y=3\\n\",\n    \"x+y\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n\n\n\nNote that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren’t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells."
  },
  {
    "objectID": "api/merge.html#creating-a-merged-notebook",
    "href": "api/merge.html#creating-a-merged-notebook",
    "title": "merge",
    "section": "Creating a merged notebook",
    "text": "Creating a merged notebook\nThe approach we use is to first “unpatch” the conflicted file, regenerating the two files it was originally created from. Then we redo the diff process, but using cells instead of text lines.\n\nsource\n\nunpatch\n\n unpatch (s:str)\n\nTakes a string with conflict markers and returns the two original files, and their branch names\nThe result of “unpatching” our conflicted test notebook is the two original notebooks it would have been created from. Each of these original notebooks will contain valid JSON:\n\na,b,branch1,branch2 = unpatch(tst_nb)\ndict2nb(loads(a))\n\n{ 'cells': [ { 'cell_type': 'code',\n               'execution_count': 6,\n               'idx_': 0,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['3']},\n                              'execution_count': 6,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'z=3\\nz'},\n             { 'cell_type': 'code',\n               'execution_count': 5,\n               'idx_': 1,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['6']},\n                              'execution_count': 7,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'x=3\\ny=3\\nx+y'},\n             { 'cell_type': 'code',\n               'execution_count': None,\n               'idx_': 2,\n               'metadata': {},\n               'outputs': [],\n               'source': ''}],\n  'metadata': { 'kernelspec': { 'display_name': 'Python 3',\n                                'language': 'python',\n                                'name': 'python3'}},\n  'nbformat': 4,\n  'nbformat_minor': 2}\n\n\n\ndict2nb(loads(b))\n\n{ 'cells': [ { 'cell_type': 'code',\n               'execution_count': 6,\n               'idx_': 0,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['3']},\n                              'execution_count': 6,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'z=2\\nz'},\n             { 'cell_type': 'code',\n               'execution_count': 5,\n               'idx_': 1,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['6']},\n                              'execution_count': 5,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'x=3\\ny=3\\nx+y'},\n             { 'cell_type': 'code',\n               'execution_count': None,\n               'idx_': 2,\n               'metadata': {},\n               'outputs': [],\n               'source': ''}],\n  'metadata': { 'kernelspec': { 'display_name': 'Python 3',\n                                'language': 'python',\n                                'name': 'python3'}},\n  'nbformat': 4,\n  'nbformat_minor': 2}\n\n\n\nbranch1,branch2\n\n('HEAD', 'a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35')\n\n\n\nsource\n\n\nnbdev_fix\n\n nbdev_fix (nbname:str, outname:str=None, nobackup:<function\n            bool_arg>=True, theirs:bool=False, noprint:bool=False)\n\nCreate working notebook from conflicted notebook nbname\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnbname\nstr\n\nNotebook filename to fix\n\n\noutname\nstr\nNone\nFilename of output notebook (defaults to nbname)\n\n\nnobackup\nbool_arg\nTrue\nDo not backup nbname to nbname.bak if outname not provided\n\n\ntheirs\nbool\nFalse\nUse their outputs and metadata instead of ours\n\n\nnoprint\nbool\nFalse\nDo not print info about whether conflicts are found\n\n\n\nThis begins by optionally backing the notebook fname to fname.bak in case something goes wrong. Then it parses the broken json, solving conflicts in cells. Every conflict that only involves metadata or outputs of cells will be solved automatically by using the local (theirs==False) or the remote (theirs==True) branch. Otherwise, or for conflicts involving the inputs of cells, the json will be repaired by including the two version of the conflicted cell(s) with markdown cells indicating the conflicts. You will be able to open the notebook again and search for the conflicts (look for <<<<<<<) then fix them as you wish.\nA message will be printed indicating whether the notebook was fully merged or if conflicts remain.\n\nnbdev_fix(broken, outname='tmp.ipynb')\nchk = read_nb('tmp.ipynb')\ntest_eq(len(chk.cells), 7)\nos.unlink('tmp.ipynb')\n\nOne or more conflict remains in the notebook, please inspect manually."
  },
  {
    "objectID": "api/merge.html#git-merge-driver",
    "href": "api/merge.html#git-merge-driver",
    "title": "merge",
    "section": "Git merge driver",
    "text": "Git merge driver\n\nsource\n\nnbdev_merge\n\n nbdev_merge (base:str, ours:str, theirs:str, path:str)\n\nGit merge driver for notebooks\nThis implements a git merge driver for notebooks that automatically resolves conflicting metadata and outputs, and splits remaining conflicts as separate cells so that the notebook can be viewed and fixed in Jupyter. The easiest way to install it is by running nbdev_install_hooks.\nThis works by first running Git’s default merge driver, and then nbdev_fix if there are still conflicts. You can set nbdev_fix’s theirs argument using the THEIRS environment variable, for example:\nTHEIRS=True git merge branch"
  },
  {
    "objectID": "api/doclinks.html",
    "href": "api/doclinks.html",
    "title": "doclinks",
    "section": "",
    "text": "source\n\n\n\n patch_name (o)\n\nIf o is decorated with patch or patch_to, return its class-prefix name\n\ndef _test_patch(code): return patch_name(ast.parse(code).body[0])\ns = \"@patch\\ndef _f(self:_T): ...\"\ntest_eq('_T._f', _test_patch(s))\n\n\ns = \"@patch_to(_T)\\ndef _g(self): ...\"\ntest_eq('_T._g', _test_patch(s))\n\n\n# Get all patched classes when patching with a union\ns = \"@patch\\ndef _f(self:_T|_U|_V): ...\"\ntest_eq(_test_patch(s), ['_T._f', '_U._f', '_V._f'])\n\n\n# _build_modidx()"
  },
  {
    "objectID": "api/doclinks.html#export-a-notebook",
    "href": "api/doclinks.html#export-a-notebook",
    "title": "doclinks",
    "section": "Export a notebook",
    "text": "Export a notebook\n\nsource\n\nnbglob\n\n nbglob (path=None, skip_folder_re='^[_.]', file_glob='*.ipynb',\n         skip_file_re='^[_.]', key='nbs_path', as_path=False,\n         recursive:bool=True, symlinks:bool=True, file_re:str=None,\n         folder_re:str=None, skip_file_glob:str=None,\n         func:callable=<function join>, ret_folders:bool=False)\n\nFind all files in a directory matching an extension given a config key.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nPath | str\n\npath to start searching\n\n\nskip_folder_re\nstr\nNone\nSkip folders matching regex,\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nkey\nstr\nnbs_path\n\n\n\nas_path\nbool\nFalse\n\n\n\nrecursive\nbool\nTrue\nsearch subfolders\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\nReturns\nL\n\nPaths to matched files\n\n\n\n\nsource\n\n\nnbglob_cli\n\n nbglob_cli (path:str=None, symlinks:bool=False, file_glob:str='*.ipynb',\n             file_re:str=None, folder_re:str=None,\n             skip_file_glob:str=None, skip_file_re:str='^[_.]',\n             skip_folder_re:str='^[_.]')\n\nFind all files in a directory matching an extension given a config key.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nsource\n\n\nnbdev_export\n\n nbdev_export (path:str=None, symlinks:bool=False,\n               file_glob:str='*.ipynb', file_re:str=None,\n               folder_re:str=None, skip_file_glob:str=None,\n               skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nExport notebooks in path to Python modules\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath or filename\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex"
  },
  {
    "objectID": "api/doclinks.html#query-the-module-index",
    "href": "api/doclinks.html#query-the-module-index",
    "title": "doclinks",
    "section": "Query the module index",
    "text": "Query the module index\n\na = Path('a/b.c')\n\n\na.parts\n\n('a', 'b.c')\n\n\n\nsource\n\nNbdevLookup\n\n NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None)\n\nMapping from symbol names to docs and source URLs\nIndexing returns a link to the symbol’s docs, along with the name of the source file the source URL if available.\n\nc = NbdevLookup()\nc['nbdev.doclinks.NbdevLookup']\n\n('https://nbdev.fast.ai/api/doclinks.html#nbdevlookup',\n 'nbdev/doclinks.py',\n 'https://github.com/fastai/nbdev/blob/master/nbdev/doclinks.py')\n\n\n\nsource\n\n\nNbdevLookup.doc\n\n NbdevLookup.doc (sym)\n\nLink to docs for sym\n\nc.doc('nbdev.doclinks.NbdevLookup')\n\n'https://nbdev.fast.ai/api/doclinks.html#nbdevlookup'\n\n\nSymbol names are taken from libraries registered using the ‘nbdev’ entry point. By default, all libraries with this entry point are searched, but full symbol names (including module prefix) are required.\n\nassert c.doc('numpy.array').startswith('http')\nassert c.doc('NbdevLookup').endswith('#nbdevlookup')\nassert not c.doc('array')\n\nPass strip_libs to list libraries which should be available without requiring a module prefix.\n\nc = NbdevLookup(strip_libs=('nbdev', 'nbdev_numpy'))\nassert c.doc('array').startswith('http')\n\n\nsource\n\n\nNbdevLookup.code\n\n NbdevLookup.code (sym)\n\nLink to source code for sym\n\nNbdevLookup().code('fastcore.net.urlsend')\n\n'https://github.com/fastai/fastcore/blob/master/fastcore/net.py#LNone'\n\n\n\nsource\n\n\nNbdevLookup.linkify\n\n NbdevLookup.linkify (md)\n\n\nmd = \"\"\"This is a link to `numpy.array` and to `get_config` but not a link to `foobar`.\nAnd not a link to <code>dict2nb</code>.\n\n    This is not a link to `get_config`\nThis isn’t a link to get_config either\n\n\n\nprint(NbdevLookup('nbdev').linkify(md))\n\nThis is a link to [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array) and to [`get_config`](https://nbdev.fast.ai/API/config.html#get_config) but not a link to `foobar`.\nAnd not a link to <code>dict2nb</code>.\n\n    This is not a link to `get_config`\n\nThis isn’t a link to get_config either"
  },
  {
    "objectID": "api/test.html",
    "href": "api/test.html",
    "title": "test",
    "section": "",
    "text": "source\n\ntest_nb\n\n test_nb (fn, skip_flags=None, force_flags=None, do_print=False,\n          showerr=True, basepath=None)\n\nExecute tests in notebook in fn except those with skip_flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfn\n\n\nfile name of notebook to test\n\n\nskip_flags\nNoneType\nNone\nlist of flags marking cells to skip\n\n\nforce_flags\nNoneType\nNone\nlist of flags marking cells to always run\n\n\ndo_print\nbool\nFalse\nprint completion?\n\n\nshowerr\nbool\nTrue\nprint errors to stderr?\n\n\nbasepath\nNoneType\nNone\npath to add to sys.path\n\n\n\ntest_nb can test a notebook, and skip over certain flags:\n\n_nb = Path('../../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, skip_flags=['notest'])\nassert success\n\nIn that notebook the cell flagged notest raises an exception, which will be returned as a bool:\n\n_nb = Path('../../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, showerr=False)\nassert not success\n\nSometimes you may wish to override one or more of the skip_flags, in which case you can use the argument force_flags which will remove the appropriate tag(s) from skip_flags. This is useful because skip_flags are meant to be set in the tst_flags field of settings.ini, whereas force_flags are usually passed in by the user.\n\nsource\n\n\nnbdev_test\n\n nbdev_test (path:str=None, flags:str='', n_workers:int=None,\n             timing:bool=False, do_print:bool=False, pause:float=0.01,\n             ignore_fname:str='.notest', symlinks:bool=False,\n             file_glob:str='*.ipynb', file_re:str=None,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nTest in parallel notebooks matching path, passing along flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nA notebook name or glob to test\n\n\nflags\nstr\n\nSpace separated list of test flags to run that are normally ignored\n\n\nn_workers\nint\nNone\nNumber of workers\n\n\ntiming\nbool\nFalse\nTime each notebook to see which are slow\n\n\ndo_print\nbool\nFalse\nPrint start and end of each notebook\n\n\npause\nfloat\n0.01\nPause time (in seconds) between notebooks to avoid race conditions\n\n\nignore_fname\nstr\n.notest\nFilename that will result in siblings being ignored\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nnbdev_test(n_workers=0)\n\nSuccess.\n\n\nYou can even run nbdev_test in non nbdev projects, for example, you can test an individual notebook like so:\nnbdev_test --path ../../tests/minimal.ipynb --do_print\nOr you can test an entire directory of notebooks filtered for only those that match a regular expression:\nnbdev_test --path ../../tests --file_re '.*test.ipynb' --do_print"
  },
  {
    "objectID": "api/clean.html",
    "href": "api/clean.html",
    "title": "clean",
    "section": "",
    "text": "To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with nbdev_install_hooks). The following functions are used to do that."
  },
  {
    "objectID": "api/clean.html#trust",
    "href": "api/clean.html#trust",
    "title": "clean",
    "section": "Trust",
    "text": "Trust\n\nsource\n\nnbdev_trust\n\n nbdev_trust (fname:str=None, force_all:bool=False)\n\nTrust notebooks matching fname\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to trust\n\n\nforce_all\nbool\nFalse\nAlso trust notebooks that haven’t changed"
  },
  {
    "objectID": "api/clean.html#clean",
    "href": "api/clean.html#clean",
    "title": "clean",
    "section": "Clean",
    "text": "Clean\n\nsource\n\nclean_nb\n\n clean_nb (nb, clear_all=False, allowed_metadata_keys:list=None,\n           allowed_cell_metadata_keys:list=None, clean_ids=True)\n\nClean nb from superfluous metadata\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnb\n\n\nThe notebook to clean\n\n\nclear_all\nbool\nFalse\nRemove all cell metadata and cell outputs\n\n\nallowed_metadata_keys\nlist\nNone\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nlist\nNone\nPreserve the list of keys in cell level metadata\n\n\nclean_ids\nbool\nTrue\nRemove ids from plaintext reprs?\n\n\n\nThe test notebook has metadata in both the main metadata section and contains cell level metadata in the second cell:\n\ntest_nb = read_nb('../../tests/metadata.ipynb')\n\nassert {'meta', 'jekyll', 'my_extra_key', 'my_removed_key'} <= test_nb.metadata.keys()\nassert {'meta', 'hide_input', 'my_extra_cell_key', 'my_removed_cell_key'} == test_nb.cells[1].metadata.keys()\n\nAfter cleaning the notebook, all extra metadata is removed, only some keys are allowed by default:\n\nclean_nb(test_nb)\n\nassert {'jekyll', 'kernelspec'} == test_nb.metadata.keys()\nassert {'hide_input'} == test_nb.cells[1].metadata.keys()\n\nWe can preserve some additional keys at the notebook or cell levels:\n\ntest_nb = read_nb('../../tests/metadata.ipynb')\nclean_nb(test_nb, allowed_metadata_keys={'my_extra_key'}, allowed_cell_metadata_keys={'my_extra_cell_key'})\n\nassert {'jekyll', 'kernelspec', 'my_extra_key'} == test_nb.metadata.keys()\nassert {'hide_input', 'my_extra_cell_key'} == test_nb.cells[1].metadata.keys()\n\nPassing clear_all=True removes everything from the cell metadata:\n\ntest_nb = read_nb('../../tests/metadata.ipynb')\nclean_nb(test_nb, clear_all=True)\n\nassert {'jekyll', 'kernelspec'} == test_nb.metadata.keys()\ntest_eq(test_nb.cells[1].metadata, {})\n\nPassing clean_ids=True removes ids from plaintext repr outputs, to avoid notebooks whose contents change on each run since they often lead to git merge conflicts. For example:\n<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FB4F8979690>\nbecomes:\n<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>\n\nsource\n\n\nprocess_write\n\n process_write (warn_msg, proc_nb, f_in, f_out=None, disp=False)\n\n\nsource\n\n\nnbdev_clean\n\n nbdev_clean (fname:str=None, clear_all:bool=False, disp:bool=False,\n              stdin:bool=False)\n\nClean all notebooks in fname to avoid merge conflicts\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to clean\n\n\nclear_all\nbool\nFalse\nClean all metadata and outputs\n\n\ndisp\nbool\nFalse\nPrint the cleaned outputs\n\n\nstdin\nbool\nFalse\nRead notebook from input stream\n\n\n\nBy default (fname left to None), all the notebooks in lib_folder are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing clear_all=True.\nIf you want to keep some keys in the main notebook metadata you can set allowed_metadata_keys in settings.ini. Similarly for cell level metadata use: allowed_cell_metadata_keys. For example, to preserve both k1 and k2 at both the notebook and cell level adding the following in settings.ini:\n...\nallowed_metadata_keys = k1 k2\nallowed_cell_metadata_keys = k1 k2\n...\n\nsource\n\n\nclean_jupyter\n\n clean_jupyter (path, model, **kwargs)\n\nClean Jupyter model pre save to path\nThis cleans notebooks on-save to avoid unnecessary merge conflicts. The easiest way to install it for both Jupyter Notebook and Lab is by running nbdev_install_hooks. It works by implementing a pre_save_hook from Jupyter’s file save hook API."
  },
  {
    "objectID": "api/clean.html#hooks",
    "href": "api/clean.html#hooks",
    "title": "clean",
    "section": "Hooks",
    "text": "Hooks\n\nsource\n\nnbdev_install_hooks\n\n nbdev_install_hooks ()\n\nInstall Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nSee clean_jupyter and nbdev_merge for more about how each hook works."
  },
  {
    "objectID": "api/quarto.html",
    "href": "api/quarto.html",
    "title": "quarto",
    "section": "",
    "text": "source\n\n\n\n install_quarto ()\n\nInstall latest Quarto on macOS or Linux, prints instructions for Windows\n\nsource\n\n\n\n\n install ()\n\nInstall Quarto and the current library"
  },
  {
    "objectID": "api/quarto.html#sidebar",
    "href": "api/quarto.html#sidebar",
    "title": "quarto",
    "section": "Sidebar",
    "text": "Sidebar\n\nsource\n\nnbdev_sidebar\n\n nbdev_sidebar (path:str=None, printit:bool=False, force:bool=False,\n                skip_folder_re:str='(?:^[_.]|^www\\\\$)',\n                file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$',\n                symlinks:bool=False, folder_re:str=None,\n                skip_file_glob:str=None, skip_file_re:str='^[_.]')\n\nCreate sidebar.yml\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nprintit\nbool\nFalse\nPrint YAML for debugging\n\n\nforce\nbool\nFalse\nCreate sidebar even if settings.ini custom_sidebar=False\n\n\nskip_folder_re\nstr\n(?:^[_.]|^www$)\nSkip folders matching regex\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\n\n\n# nbdev_sidebar(printit=True, force=True)"
  },
  {
    "objectID": "api/quarto.html#render-docs",
    "href": "api/quarto.html#render-docs",
    "title": "quarto",
    "section": "Render docs",
    "text": "Render docs\n\nsource\n\nrefresh_quarto_yml\n\n refresh_quarto_yml ()\n\nGenerate _quarto.yml from settings.ini.\n\nsource\n\n\nnbdev_readme\n\n nbdev_readme (path:str=None, chk_time:bool=False)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nchk_time\nbool\nFalse\nOnly build if out of date\n\n\n\n\nsource\n\n\nnbdev_docs\n\n nbdev_docs (path:str=None, n_workers:int=2, file_glob:str=None,\n             file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nCreate Quarto docs and README.md\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nn_workers\nint\n2\nNumber of workers\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nsource\n\n\ndeploy\n\n deploy (path:str=None, skip_build:bool=False, n_workers:int=2,\n         file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$',\n         symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None,\n         skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nDeploy docs to GitHub Pages\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nskip_build\nbool\nFalse\nDon’t build docs first\n\n\nn_workers\nint\n2\nNumber of workers\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nsource\n\n\nprepare\n\n prepare ()\n\nExport, test, and clean notebooks, and render README if needed"
  },
  {
    "objectID": "api/quarto.html#preview",
    "href": "api/quarto.html#preview",
    "title": "quarto",
    "section": "Preview",
    "text": "Preview\n\nsource\n\nfs_watchdog\n\n fs_watchdog (func, path, recursive:bool=True)\n\nFile system watchdog dispatching to func\n\nsource\n\n\nnbdev_preview\n\n nbdev_preview (path:str=None, port:int=None, host:str=None,\n                n_workers:int=2, file_glob:str=None,\n                file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False,\n                folder_re:str=None, skip_file_glob:str=None,\n                skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nPreview docs locally\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nport\nint\nNone\nThe port on which to run preview\n\n\nhost\nstr\nNone\nThe host on which to run preview\n\n\nn_workers\nint\n2\nNumber of workers\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex"
  },
  {
    "objectID": "api/showdoc.html",
    "href": "api/showdoc.html",
    "title": "showdoc",
    "section": "",
    "text": "Render nicely formatted tables that shows docments for any function or method.\n\nsource\n\n\n\n DocmentTbl (obj, verbose=True, returns=True)\n\nCompute the docment table string\nDocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function:\n\ndef _f(a,      # description of param a \n       b=True, # description of param b\n       c:str=None\n       ) -> int: ...\n\n_dm = DocmentTbl(_f)\n_dm\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\nReturns\nint\n\n\n\n\n\n\n\nIf one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered:\n\ndef _f(a, \n        b, #param b\n        c  #param c\n       ): ...\n\n_dm2 = DocmentTbl(_f)\n_dm2\n\n\n\n\n\nDetails\n\n\n\n\na\n\n\n\nb\nparam b\n\n\nc\nparam c\n\n\n\n\n\nDocmentTbl also works on classes. By default, the __init__ will be rendered:\n\nclass _Test:\n    def __init__(self, \n                 a,      # description of param a \n                 b=True, # description of param b\n                 c:str=None):\n        ...\n        \n    def foo(self, \n            c:int,      # description of param c\n            d=True, # description of param d\n           ):\n        ...\n\n\nDocmentTbl(_Test)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\n\n\n\nYou can also pass a method to be rendered as well:\n\nDocmentTbl(_Test.foo)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nc\nint\n\ndescription of param c\n\n\nd\nbool\nTrue\ndescription of param d"
  },
  {
    "objectID": "api/showdoc.html#documentation-for-an-object",
    "href": "api/showdoc.html#documentation-for-an-object",
    "title": "showdoc",
    "section": "Documentation For An Object",
    "text": "Documentation For An Object\nRender the signature as well as the docments to show complete documentation for an object.\n\nsource\n\nShowDocRenderer\n\n ShowDocRenderer (sym, name:str|None=None, title_level:int=3)\n\nShow documentation for sym\n\nsource\n\n\nBasicMarkdownRenderer\n\n BasicMarkdownRenderer (sym, name:str|None=None, title_level:int=3)\n\nMarkdown renderer for show_doc\n\nsource\n\n\nshow_doc\n\n show_doc (sym, renderer=None, name:str|None=None, title_level:int=3)\n\nShow signature and docstring for sym\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsym\n\n\nSymbol to document\n\n\nrenderer\nNoneType\nNone\nOptional renderer (defaults to markdown)\n\n\nname\nstr | None\nNone\nOptionally override displayed name of sym\n\n\ntitle_level\nint\n3\nHeading level to use for symbol name\n\n\n\nYou can use show_doc to document apis of functions, classes or methods.\n\n\nNumpy Docstrings\nif you have numpy docstrings instead of docments, show_doc will attempt to parse and render those just like docments.\n\n\n\n\n\n\nWarning\n\n\n\nNumpy docstring formatting is very strict. If your docstrings do not strictly adhere to the numpy format, it will not be parsed properly and information about parameters and return values may not properly be rendered in the table below the signature. Where possible, we recommend using docments to annonate your function instead."
  },
  {
    "objectID": "api/showdoc.html#show_doc-on-classes",
    "href": "api/showdoc.html#show_doc-on-classes",
    "title": "showdoc",
    "section": "show_doc on Classes",
    "text": "show_doc on Classes\nshow_doc works on Classes, too, including when you use @patch.\nYou can define methods for the class Foo with @patch which is convenient in allowing you to break up code for documentation in notebooks.\nClass properties also work with showdoc."
  },
  {
    "objectID": "api/showdoc.html#pluggable-renderers",
    "href": "api/showdoc.html#pluggable-renderers",
    "title": "showdoc",
    "section": "Pluggable renderers",
    "text": "Pluggable renderers\nYou can replace the default markdown show_doc renderer with custom renderers. For instance, nbdev comes with a simple example for rendering with raw HTML.\n\nsource\n\nBasicHtmlRenderer\n\n BasicHtmlRenderer (sym, name:str|None=None, title_level:int=3)\n\nSimple HTML renderer for show_doc\n\nsource\n\n\ndoc\n\n doc (elt)\n\nShow show_doc info along with link to docs\n\nsource\n\n\nshowdoc_nm\n\n showdoc_nm (tree)\n\nGet the fully qualified name for showdoc."
  },
  {
    "objectID": "api/showdoc.html#other-helpers",
    "href": "api/showdoc.html#other-helpers",
    "title": "showdoc",
    "section": "Other helpers",
    "text": "Other helpers\n\nsource\n\ncolab_link\n\n colab_link (path)\n\nGet a link to the notebook at path on Colab\n\ncolab_link('index')\n\nOpen index in Colab"
  },
  {
    "objectID": "api/release.html",
    "href": "api/release.html",
    "title": "release",
    "section": "",
    "text": "nbdev.release provides 3 commands that you can run from your shell to manage your changelog file and git releases:\n\nnbdev_changelog: creates a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_release_git: tags and creates a release in GitHub for the current version\nnbdev_release_gh: calls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\nIt provides 3 futher commands for releasing packages on pypi or conda:\n\nnbdev_pypi: Create and upload a pypi installer\nnbdev_conda: Create and upload a conda installer\nnbdev_release_both: Create and upload both pypi and conda installers\n\nHere’s a brief demonstration of how to use the changelog and git release tools in nbdev.release. This demo first creates an issue using the gh command line tool, and then closes it using git; you can also use GitHub’s web interface for both of these tasks. (Note that this functionality used to be in a project called fastrelease, so in the video the command line tools have different names, starting with fastrelease_ instead of nbdev_).\n\n\n\n\n\n\n\nYou’ll need to get a GitHub personal access token if you haven’t already. To do so, click here and enter “nbdev” in the “Note” section, and click the repo checkbox.\nThen click “Generate Token” at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token.\n\nPaste that token into a file called token into the root of your repo. You can run the following in your terminal (cd to the root of your repo first) to create that file:\necho XXX > token\nReplace XXX above with the token you copied. Also, ensure that this file isn’t added to git, by running this in your terminal:\necho token >> .gitignore\n\n\n\nNow you’re ready to create your release notes. These are created in a file called CHANGELOG.md. Here’s an example of what it creates: nbdev CHANGELOG.\nAll issues with the label bug, enhancement, or breaking that have been closed in your repo since your last release will be added to the top of this file. If you haven’t made any releases before, then all issues with those labels will be included.\nTherefore, before you create or update CHANGELOG.md, go to your GitHub issues page, remove is:open from the filter, and label any issues you want included with one of the labels above. When you’ve done that, you can create or update your release notes by running in your terminal:\nnbdev_changelog\nThe titles and bodies of each issue will be added. Open CHANGELOG.md in your editor and make any edits that you want, and then commit the file to your repo (remember to git add it!)\n\n\n\nYou should now tag a release. This will create a tag in GitHub with your current version number in settings.ini, and will then make it into a release, using your latest release notes as the description of the release:\nnbdev_release_git\nAfter you run this, be sure to increment your version number in settings.ini. You can either edit it manually, or if you use nbdev it can be done for you by running:\nnbdev_bump_version\n\n\n\nTo complete both of the steps above, run:\nnbdev_release_gh\nSee the screencast above for a demonstration of this."
  },
  {
    "objectID": "api/release.html#python-api",
    "href": "api/release.html#python-api",
    "title": "release",
    "section": "Python API",
    "text": "Python API\n\nsource\n\nRelease\n\n Release (owner=None, repo=None, token=None, **groups)\n\nCreate CHANGELOG.md from GitHub issues\nTo create a markdown changelog, first create a Release object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named token at the root of your repo. Release attempts to fetch values for arguments from the following locations if not supplied:\n\nowner: fetched from the field user in settings.ini. This is the owner name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastai.\nrepo: fetched from the field lib_name in settings.ini. This is the name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastcore.\ntoken: fetched from a file named token at the root of your repo. Creating a token is discussed in the setup section.\ngroups: (optional) fetched from the field label_groups in settings.ini, which is a JSON string. This is a mapping from label names to titles in your release notes. If not specified, this defaults to:\n\n{\"breaking\": \"Breaking Changes\", \"enhancement\":\"New Features\", \"bug\":\"Bugs Squashed\"}\n\nsource\n\n\nRelease.changelog\n\n Release.changelog (debug=False)\n\nCreate the CHANGELOG.md file, or return the proposed text if debug is True\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndebug\nbool\nFalse\nJust print the latest changes, instead of updating file\n\n\n\n\nrel = Release()\n# print(rel.changelog(debug=True))\n\n\nsource\n\n\nRelease.release\n\n Release.release ()\n\nTag and create a release in GitHub for the current version\nThis uses the version information from your settings.ini.\n\nsource\n\n\nRelease.latest_notes\n\n Release.latest_notes ()\n\nLatest CHANGELOG entry\nAll relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings."
  },
  {
    "objectID": "api/release.html#cli-functions",
    "href": "api/release.html#cli-functions",
    "title": "release",
    "section": "CLI functions",
    "text": "CLI functions\n\nsource\n\nchangelog\n\n changelog (debug:<function store_true>=False, repo:str=None)\n\nCreate a CHANGELOG.md file from closed and labeled GitHub issues\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndebug\nstore_true\nFalse\nPrint info to be added to CHANGELOG, instead of updating file\n\n\nrepo\nstr\nNone\nrepo to use instead of lib_name from settings.ini\n\n\n\n\nsource\n\n\nrelease_git\n\n release_git (token:str=None)\n\nTag and create a release in GitHub for the current version\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\nNone\nOptional GitHub token (otherwise token file is used)\n\n\n\n\nsource\n\n\nrelease_gh\n\n release_gh (token:str=None)\n\nCalls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\nNone\nOptional GitHub token (otherwise token file is used)"
  },
  {
    "objectID": "api/release.html#publish-packages",
    "href": "api/release.html#publish-packages",
    "title": "release",
    "section": "Publish Packages",
    "text": "Publish Packages\n\nsource\n\npypi_json\n\n pypi_json (s)\n\nDictionary decoded JSON for PYPI path s\n\nsource\n\n\nlatest_pypi\n\n latest_pypi (name)\n\nLatest version of name on pypi\n\nsource\n\n\npypi_details\n\n pypi_details (name)\n\nVersion, URL, and SHA256 for name from pypi\n\nsource\n\n\nconda_output_path\n\n conda_output_path (name)\n\nOutput path for conda build\n\nsource\n\n\nwrite_conda_meta\n\n write_conda_meta (path='conda')\n\nWrites a meta.yaml file to the conda directory of the current directory\nThis function is used in the conda_package CLI command.\nNB: you need to first of all upload your package to PyPi, before creating the conda package.\n\nsource\n\n\nanaconda_upload\n\n anaconda_upload (name, loc=None, user=None, token=None, env_token=None)\n\nUpload name to anaconda\n\nsource\n\n\nrelease_conda\n\n release_conda (path:str='conda', do_build:<function bool_arg>=True,\n                build_args:str='', skip_upload:<function\n                store_true>=False, mambabuild:<function store_true>=False,\n                upload_user:str=None)\n\nCreate a meta.yaml file ready to be built into a package, and optionally build and upload it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\n\n\nsource\n\n\nchk_conda_rel\n\n chk_conda_rel (nm:str, apkg:str=None, channel:str='fastai',\n                force:<function store_true>=False)\n\nPrints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnm\nstr\n\nPackage name on pypi\n\n\napkg\nstr\nNone\nAnaconda Package (defaults to {nm})\n\n\nchannel\nstr\nfastai\nAnaconda Channel\n\n\nforce\nstore_true\nFalse\nAlways return github tag\n\n\n\nTo build and upload a conda package, cd to the root of your repo, and then:\nnbdev_conda_package\nOr to do things more manually:\nnbdev_conda_package --do_build false\ncd conda\nconda build --no-anaconda-upload --output-folder build {name}\nanaconda upload build/noarch/{name}-{ver}-*.tar.bz2\nAdd --debug to the conda build command to debug any problems that occur. Note that the build step takes a few minutes. Add -u {org_name} to the anaconda upload command if you wish to upload to an organization, or pass upload_user to nbdev_conda_package.\nNB: you need to first of all upload your package to PyPi, before creating the conda package.\n\nsource\n\n\nrelease_pypi\n\n release_pypi (repository:str='pypi')\n\nCreate and upload Python package to PyPI\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepository\nstr\npypi\nRespository to upload to (defined in ~/.pypirc)\n\n\n\n\nsource\n\n\nrelease_both\n\n release_both (path:str='conda', do_build:<function bool_arg>=True,\n               build_args:str='', skip_upload:<function store_true>=False,\n               mambabuild:<function store_true>=False,\n               upload_user:str=None, repository:str='pypi')\n\nRelease both conda and PyPI packages\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\nrepository\nstr\npypi\nPypi respository to upload to (defined in ~/.pypirc)"
  },
  {
    "objectID": "api/release.html#bump-version",
    "href": "api/release.html#bump-version",
    "title": "release",
    "section": "Bump Version",
    "text": "Bump Version\n\nsource\n\nbump_version\n\n bump_version (version, part=2, unbump=False)\n\n\nsource\n\n\nnbdev_bump_version\n\n nbdev_bump_version (part:int=2, unbump:bool=False)\n\nIncrement version in settings.ini by one\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npart\nint\n2\nPart of version to bump\n\n\nunbump\nbool\nFalse\nReduce version instead of increasing it"
  },
  {
    "objectID": "api/sync.html",
    "href": "api/sync.html",
    "title": "sync",
    "section": "",
    "text": "The library is primarily developed in notebooks so any big changes should be made there. But sometimes, it’s easier to fix small bugs or typos in the modules directly. nbdev_update_lib is the function that will propagate those changes back to the corresponding notebooks. Note that you can’t create new cells or reorder cells with that functionality, so your corrections should remain limited.\n\nsource\n\nabsolute_import\n\n absolute_import (name, fname, level)\n\nUnwarps a relative import in name according to fname\n\ntest_eq(absolute_import('xyz', 'nbdev', 0), 'xyz')\ntest_eq(absolute_import('', 'nbdev', 1), 'nbdev')\ntest_eq(absolute_import('core', 'nbdev', 1), 'nbdev.core')\ntest_eq(absolute_import('core', 'nbdev/vision', 2), 'nbdev.core')\ntest_eq(absolute_import('transform', 'nbdev/vision', 1), 'nbdev.vision.transform')\ntest_eq(absolute_import('notebook.core', 'nbdev/data', 2), 'nbdev.notebook.core')\n\n\nsource\n\n\nnbdev_update\n\n nbdev_update (fname:str=None)\n\nPropagate change in modules matching fname to notebooks that created them\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA Python file name to update"
  }
]